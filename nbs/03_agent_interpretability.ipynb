{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e949ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71553ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "causal_template = json.load(open(\"input/2_causal_interpretability.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d99946",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "\n",
    "    #model = \"ollama/codellama:13b\", #13b\n",
    "    model = \"ollama/gpt-oss:latest\", #20b\n",
    "    #model = \"ollama/devstral:latest\", #24b\n",
    "   # model = \"ollama/mistral-small:latest\", #22b\n",
    "    base_url = \"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de4007",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e19301",
   "metadata": {},
   "source": [
    "## Scenario A: Code generation text2code task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81750c8",
   "metadata": {},
   "source": [
    "### Step 1: Define the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1aab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_a = causal_template['scenario_a']['step1']['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02ffb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variable in the json file {FACTORS}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the function {FUNCTION}, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the {FUNCTION} function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec6c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages_a[1]['content'] =' '.join([messages_a[0]['content'], messages_a[1]['content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84fa354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages_a[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94ac9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_name(response):\n",
    "    match = re.search(r\"def\\s+(\\w+)\\s*\\(\", response)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffcaeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_messages(message,function, json_factors,node, test, summary):\n",
    "    #new_message= re.sub(r\"\\[.*?\\]\",\"\", message['content'])\n",
    "    new_message= message['content']\n",
    "    if function:\n",
    "        new_message = re.sub(r\"\\{FUNCTION\\}\",function, new_message)\n",
    "    if json_factors:\n",
    "        new_message = re.sub(r\"\\{FACTORS\\}\",json_factors, new_message)\n",
    "    if re.search(r\"\\{NODE\\}\", new_message):\n",
    "        new_message = re.sub(r\"\\{NODE\\}\",node, new_message)\n",
    "    if re.search(r\"\\{TEST\\}\", new_message):\n",
    "        new_message = re.sub(r\"\\{TEST\\}\",test, new_message)\n",
    "    if re.search(r\"\\{SUMMARY\\}\", new_message):\n",
    "        new_message = re.sub(r\"\\{SUMMARY\\}\",summary, new_message)\n",
    "       \n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9dc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_name(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            if k == \"name\":\n",
    "                yield v\n",
    "            else:\n",
    "                yield from find_name(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            yield from find_name(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15851135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_introspection_factors(introspection_chat_history):\n",
    "    factors = []\n",
    "    function = None\n",
    "    function_message = introspection_chat_history[3]['content']\n",
    "    function = extract_function_name(function_message)\n",
    "    factors_message = introspection_chat_history[5]['content']\n",
    "    cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", factors_message.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    data = json.loads(cleaned)\n",
    "    factors=list(find_name(data))\n",
    "    return function, function_message, factors, factors_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dca6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.\n",
      "-----\n",
      "I’d love to help you sketch out the causal graph and write counterfactual explanations, but I need to know which variables you’re working with. Could you please list the variables (and any known relationships or constraints) you’d like me to analyze? Once I have that, I can infer the most plausible causal structure and draft the requested counterfactuals.\n",
      "[CAUSAL TASK] Giving the following variable in the json file ```json\n",
      "{\n",
      "  \"A\": {\n",
      "    \"name\": \"Type hint usage\",\n",
      "    \"description\": \"Adding explicit type hints (Sequence[float], List[float]) clarifies expected inputs and outputs, improving static analysis and developer experience.\",\n",
      "    \"attribution_weight\": 0.20\n",
      "  },\n",
      "  \"B\": {\n",
      "    \"name\": \"Input validation\",\n",
      "    \"description\": \"Checking that both vectors have exactly three elements ensures the function behaves correctly and prevents subtle bugs.\",\n",
      "    \"attribution_weight\": 0.20\n",
      "  },\n",
      "  \"C\": {\n",
      "    \"name\": \"Error handling\",\n",
      "    \"description\": \"Raising a ValueError with a clear message helps callers quickly identify misuse of the API.\",\n",
      "    \"attribution_weight\": 0.15\n",
      "  },\n",
      "  \"D\": {\n",
      "    \"name\": \"Documentation string\",\n",
      "    \"description\": \"A comprehensive docstring (including parameters, returns, and examples) aids readability, IDE assistance, and future maintenance.\",\n",
      "    \"attribution_weight\": 0.15\n",
      "  },\n",
      "  \"E\": {\n",
      "    \"name\": \"Function name\",\n",
      "    \"description\": \"Choosing a concise, descriptive name (cross_product) makes the intent immediately obvious.\",\n",
      "    \"attribution_weight\": 0.10\n",
      "  },\n",
      "  \"F\": {\n",
      "    \"name\": \"Return type\",\n",
      "    \"description\": \"Returning a concrete List[float] rather than a generic Sequence improves usability for callers expecting a mutable sequence.\",\n",
      "    \"attribution_weight\": 0.10\n",
      "  },\n",
      "  \"G\": {\n",
      "    \"name\": \"Code readability\",\n",
      "    \"description\": \"Using clear variable names (a1, a2, a3, etc.) and straightforward arithmetic enhances understandability and maintainability.\",\n",
      "    \"attribution_weight\": 0.10\n",
      "  }\n",
      "}\n",
      "```, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the function cross_product, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.\n",
      "-----\n",
      "Here’s a compact causal graph that shows how the seven design‑choice variables (A–G) influence one another and, ultimately, the generation of the `cross_product` function.  \n",
      "The graph is written in **Graphviz DOT** syntax and ready to be visualised with any Graphviz‑compatible renderer.\n",
      "\n",
      "```dot\n",
      "digraph cross_product_causal_graph {\n",
      "  /* Basic styling */\n",
      "  node [shape=box, style=filled, fillcolor=\"#f0f8ff\", fontname=Helvetica];\n",
      "  edge [fontname=Helvetica];\n",
      "\n",
      "  /* Nodes – one per design variable + the code‑generation outcome */\n",
      "  A [label=\"A\\nType hint usage\\n(0.20)\"];\n",
      "  B [label=\"B\\nInput validation\\n(0.20)\"];\n",
      "  C [label=\"C\\nError handling\\n(0.15)\"];\n",
      "  D [label=\"D\\nDocumentation string\\n(0.15)\"];\n",
      "  E [label=\"E\\nFunction name\\n(0.10)\"];\n",
      "  F [label=\"F\\nReturn type\\n(0.10)\"];\n",
      "  G [label=\"G\\nCode readability\\n(0.10)\"];\n",
      "  CodeGen [label=\"Code Generation\\n(cross_product)\"];\n",
      "\n",
      "  /* Core causal links between design choices */\n",
      "  A -> B;      /* Type hints encourage explicit validation */\n",
      "  A -> F;      /* Type hints inform the concrete return type */\n",
      "  B -> C;      /* Validation errors feed into error handling */\n",
      "  D -> G;      /* A rich docstring improves readability */\n",
      "  E -> D;      /* A good name makes the docstring clearer */\n",
      "  F -> G;      /* Return type consistency boosts readability */\n",
      "  F -> D;      /* Concrete return type helps the docstring */\n",
      "  E -> G;      /* A descriptive name aids readability */\n",
      "  D -> C;      /* Documentation may dictate error‑handling style */\n",
      "\n",
      "  /* All variables influence the final code generation */\n",
      "  A -> CodeGen;\n",
      "  B -> CodeGen;\n",
      "  C -> CodeGen;\n",
      "  D -> CodeGen;\n",
      "  E -> CodeGen;\n",
      "  F -> CodeGen;\n",
      "  G -> CodeGen;\n",
      "}\n",
      "```\n",
      "\n",
      "### How to read the graph\n",
      "* **Directed edges (`->`)** represent a causal influence.\n",
      "* For example, the edge `A -> B` means “adding explicit type hints (A) tends to make the author include more thorough input validation (B).”\n",
      "* Each design variable also points directly to **`Code Generation`** because it ultimately contributes to how the `cross_product` function is written.\n",
      "* The weights (in parentheses) are just the attribution scores you supplied; they’re shown in the node labels for reference but don’t alter the causal structure.\n",
      "\n",
      "You can paste this DOT code into any Graphviz viewer (e.g., `dot -Tpng file.dot -o out.png`) to visualise the causal relationships.\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Type hint usage during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing_Input_Validation\": {\n",
      "    \"description\": \"The function would likely be written without checks that both vectors have exactly three elements, increasing the risk of silent errors.\",\n",
      "    \"rationale\": [\n",
      "      \"A (Type hint usage) is a direct cause of B (Input validation).\",\n",
      "      \"Without A, the incentive to add B is weakened, making it more probable that the author skips validation.\",\n",
      "      \"B is also a precursor to C (Error handling). Without B, C may also be omitted, compounding the risk.\",\n",
      "      \"The absence of validation is therefore a direct downstream effect of not considering type hints.\"\n",
      "    ],\n",
      "    \"probability\": 0.75\n",
      "  },\n",
      "  \"Unclear_Return_Type\": {\n",
      "    \"description\": \"The function would return a generic Sequence[float] or even a raw tuple, leading callers to have to cast or convert the result.\",\n",
      "    \"rationale\": [\n",
      "      \"A influences F (Return type) by encouraging a concrete List[float] when type hints are present.\",\n",
      "      \"Without A, the author has no explicit guidance to choose a concrete return type, increasing the chance of a vague or generic type.\",\n",
      "      \"F also affects G (Code readability) and D (Documentation). A missing concrete type can make both documentation and readability poorer.\",\n",
      "      \"Thus, omitting A increases the likelihood of an unclear or generic return type.\"\n",
      "    ],\n",
      "    \"probability\": 0.60\n",
      "  },\n",
      "  \"Lower_Readability_and_Documentation_Quality\": {\n",
      "    \"description\": \"The overall code would be less readable, and the accompanying docstring would be terse or absent, reducing maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"A affects F, which in turn feeds into G (Code readability).\",\n",
      "      \"F also influences D (Documentation string), which itself influences G.\",\n",
      "      \"E (Function name) and G are also interlinked, so the cascade from missing A can lead to weaker variable naming, fewer explanatory comments, and a shorter docstring.\",\n",
      "      \"The combined loss of type hints, clear return type, and validation reduces the motivation to write clean, well‑documented code.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the {FUNCTION} function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing_Input_Validation_Leads_to_Runtime_Errors\": {\n",
      "    \"description\": \"Without the explicit input validation step, the function would accept vectors of any length, increasing the likelihood of silent runtime failures or incorrect calculations.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, the node **B** (Input validation) directly influences **Code Generation** via the edge B → CodeGen, meaning validation is a core part of the final function.\",\n",
      "      \"Because **B** is absent, the guard that ensures each vector has exactly three elements is omitted, leaving the arithmetic expressions in the function body exposed to unexpected shapes.\",\n",
      "      \"This omission directly raises the probability of runtime errors such as index‑out‑of‑range or dimensionality mismatches when the function is invoked with malformed inputs.\",\n",
      "      \"The graph also shows that **B** → **C** (Error handling); without validation, the error‑handling logic that could catch and report such problems is less likely to be written.\",\n",
      "      \"Therefore, the absence of **B** logically leads to a higher chance of silent runtime failures.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"Reduced_Error_Handling_Robustness\": {\n",
      "    \"description\": \"The lack of input validation weakens the error‑handling strategy, so the function may propagate misleading exceptions or fail silently.\",\n",
      "    \"rationale\": [\n",
      "      \"Edge **B** → **C** in the graph indicates that validation triggers the inclusion of appropriate error handling logic.\",\n",
      "      \"When **B** is omitted, the developer has no incentive to add checks that raise informative ValueErrors or guard against unexpected inputs.\",\n",
      "      \"Consequently, the function may rely on low‑level Python errors (e.g., IndexError, TypeError) that provide little context to callers.\",\n",
      "      \"This causal chain (B absence → C absence) yields a moderate‑to‑high probability that error handling will be less robust.\"\n",
      "    ],\n",
      "    \"probability\": 0.65\n",
      "  },\n",
      "  \"Weaker_Documentation_on_Input_Constraints\": {\n",
      "    \"description\": \"Documentation may become terse or omit explicit size constraints for the input vectors, reducing code maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains an edge **D** → **G** (Documentation → Readability) and **F** → **D** (Return type → Documentation).\",\n",
      "      \"While **B** does not directly influence **D**, a missing validation step reduces the need for the docstring to describe input constraints, leading to a shorter or less detailed documentation block.\",\n",
      "      \"The absence of explicit checks in the code also decreases the motivation to document such checks, creating a subtle feedback loop where less validation leads to less documentation.\",\n",
      "      \"Thus, the causal structure supports the notion that omitting **B** increases the likelihood of weaker documentation.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"RuntimeFailuresFromUndeclaredVectorLengths\": {\n",
      "    \"description\": \"Without input validation, the function would accept vectors of any length, which could lead to silent runtime failures (e.g., IndexError or incorrect cross‑product values).\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (B → CodeGen), meaning validation is an essential part of the final function body.\",\n",
      "      \"Removing **B** eliminates the guard that checks `len(a) == 3 and len(b) == 3`, leaving the arithmetic expressions vulnerable to malformed inputs.\",\n",
      "      \"Because the code would then compute `a[0]*b[1] - a[1]*b[0]` etc. without verifying indices, a vector of length < 3 would raise an IndexError or produce incorrect results.\",\n",
      "      \"Thus the absence of **B** logically increases the probability of runtime failures due to unexpected vector sizes.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"DiminishedError‑HandlingRobustness\": {\n",
      "    \"description\": \"The function would rely on generic Python exceptions instead of clear `ValueError` messages, making it harder for callers to diagnose misuse.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains the edge **B** → **C** (Input validation → Error handling). Validation typically triggers explicit error‑handling code that raises informative exceptions.\",\n",
      "      \"If **B** is omitted, the developer has less motivation to write the `if not (len(a) == 3 and len(b) == 3): raise ValueError(...)` block, and the function may fail silently or surface low‑level errors.\",\n",
      "      \"Consequently, the error‑handling path is weaker, reducing the clarity of failure modes.\"\n",
      "    ],\n",
      "    \"probability\": 0.65\n",
      "  },\n",
      "  \"LessExplicitDocumentationOnInputConstraints\": {\n",
      "    \"description\": \"The docstring would likely omit or gloss over the requirement that each vector contain exactly three elements, lowering maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"While **B** does not directly point to **D** (Documentation string) in the graph, the absence of explicit validation reduces the incentive to document input constraints.\",\n",
      "      \"Edges **D** → **G** and **F** → **D** show that documentation quality feeds into readability and is influenced by return‑type decisions. Without validation, the code lacks a concrete check that would naturally be described in the docstring.\",\n",
      "      \"Therefore, the causal structure suggests a higher chance that the documentation will be less detailed regarding input size.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"RuntimeFailureDueToMissingValidation\": {\n",
      "    \"description\": \"The function would accept vectors of any length, leading to silent runtime errors or incorrect cross‑product results.\",\n",
      "    \"rationale\": [\n",
      "      \"The causal graph shows an edge B → CodeGen, meaning input validation directly shapes the generated code.\",\n",
      "      \"Without B, the guard `len(a) == 3 and len(b) == 3` is omitted, leaving arithmetic expressions that assume three elements.\",\n",
      "      \"When a vector of length < 3 is passed, the code will raise an IndexError or compute wrong values, thus increasing failure probability.\",\n",
      "      \"Therefore, omitting B logically raises the chance of runtime failures caused by malformed inputs.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"ReducedErrorHandlingRobustness\": {\n",
      "    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains the edge B → C (Input validation → Error handling).\",\n",
      "      \"When B is absent, the developer has no explicit trigger to add an error‑handling block that raises informative exceptions.\",\n",
      "      \"Consequently, failures would surface as generic IndexError or TypeError, reducing clarity for callers.\",\n",
      "      \"Thus, omitting B increases the likelihood of weaker error handling.\"\n",
      "    ],\n",
      "    \"probability\": 0.65\n",
      "  },\n",
      "  \"WeakInputConstraintsDocumentation\": {\n",
      "    \"description\": \"The docstring would likely omit or understate the requirement that each input vector contains exactly three elements, reducing maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"Although B does not directly point to D (Documentation), the absence of explicit validation decreases the motivation to document input size constraints.\",\n",
      "      \"Edges D → G and F → D show that documentation quality is tied to return type and readability, which are indirectly affected by missing validation.\",\n",
      "      \"Without a validation guard, the code lacks a concrete check that would naturally be referenced in the docstring, leading to less detailed documentation.\",\n",
      "      \"Therefore, not considering B makes weaker documentation on input constraints more probable.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"RuntimeFailureDueToMissingValidation\": {\n",
      "    \"description\": \"The function would accept vectors of any length, leading to silent runtime errors or incorrect cross‑product results.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This means the validation guard is part of the final code.\",\n",
      "      \"Without **B**, the guard `if len(a) != 3 or len(b) != 3: raise ValueError(...)` would be omitted, leaving the arithmetic expressions to assume three elements.\",\n",
      "      \"When a vector of length < 3 is passed, the code will raise an `IndexError` or produce mathematically incorrect values, so the probability of runtime failure increases dramatically.\",\n",
      "      \"Thus, the absence of **B** logically leads to a high chance of silent runtime failures caused by malformed inputs.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"ReducedErrorHandlingRobustness\": {\n",
      "    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation usually triggers explicit error‑handling code that raises informative exceptions.\",\n",
      "      \"If **B** is omitted, the developer has no explicit trigger to add an error‑handling block that raises `ValueError` with a descriptive message.\",\n",
      "      \"Consequently, failures would surface as generic `IndexError` or `TypeError`, reducing clarity for callers and making debugging more difficult.\",\n",
      "      \"Hence, not considering **B** increases the probability that error handling will be weaker.\"\n",
      "    ],\n",
      "    \"probability\": 0.62\n",
      "  },\n",
      "  \"WeakerDocumentationOnInputConstraints\": {\n",
      "    \"description\": \"The docstring would likely omit or understate the requirement that each input vector contains exactly three elements, reducing maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"Although **B** does not directly point to **D** (Documentation string), the absence of explicit validation removes a concrete check that would normally be described in the docstring.\",\n",
      "      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, which are indirectly affected when validation is missing.\",\n",
      "      \"Without a validation guard, the code lacks a clear point of reference for documenting input size constraints, leading to less detailed or absent documentation.\",\n",
      "      \"Thus, omitting **B** makes weaker documentation on input constraints more probable.\"\n",
      "    ],\n",
      "    \"probability\": 0.48\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"MissingValidationCausesRuntimeErrors\": {\n",
      "    \"description\": \"Without an explicit validation guard, the function will accept vectors of any length, leading to silent IndexErrors or mathematically incorrect results.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This means that the guard that checks `len(a) == 3 and len(b) == 3` is part of the generated code.\",\n",
      "      \"If **B** is omitted, the guard is missing. The arithmetic expressions (`a[0]*b[1] - a[1]*b[0]`, etc.) assume three elements and will fail or produce wrong values when the inputs are shorter.\",\n",
      "      \"Because the function can now be called with malformed inputs, the probability that a runtime failure occurs rises sharply.\",\n",
      "      \"Thus the absence of **B** logically leads to a high chance of runtime errors caused by unexpected vector sizes.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"WeakErrorHandling\": {\n",
      "    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation normally triggers explicit error‑handling code that raises informative exceptions.\",\n",
      "      \"When **B** is omitted, there is no incentive to add an `if not (len(a)==3 and len(b)==3): raise ValueError(...)` block. The code would fail with generic `IndexError` or `TypeError` instead.\",\n",
      "      \"Consequently, callers receive less contextual information and debugging becomes more difficult.\",\n",
      "      \"Therefore, not considering **B** increases the probability that error handling will be weaker.\"\n",
      "    ],\n",
      "    \"probability\": 0.62\n",
      "  },\n",
      "  \"InadequateDocumentationOnInputConstraints\": {\n",
      "    \"description\": \"The docstring would likely omit or downplay the requirement that each vector contain exactly three elements, reducing maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"Although **B** does not directly point to **D** (Documentation string), the absence of a concrete validation guard removes a natural point of reference that would normally be described in the docstring.\",\n",
      "      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, both of which can be affected indirectly when validation is missing.\",\n",
      "      \"Without a guard, the code lacks a clear statement of input size constraints, leading to a shorter or less detailed docstring.\",\n",
      "      \"Hence, omitting **B** makes weaker documentation on input constraints more probable.\"\n",
      "    ],\n",
      "    \"probability\": 0.48\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "{\n",
      "  \"RuntimeFailureDueToMissingValidation\": {\n",
      "    \"description\": \"The function would accept vectors of any length, causing silent IndexErrors or mathematically incorrect cross‑product results.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This edge represents the inclusion of a validation guard in the generated code.\",\n",
      "      \"When **B** is omitted, the guard `if len(a) != 3 or len(b) != 3: raise ValueError(...)` is missing, leaving the arithmetic expressions (`a[0]*b[1] - a[1]*b[0]`, etc.) to assume three elements.\",\n",
      "      \"If the function is called with a vector of length < 3, an `IndexError` will be raised or the computation will produce incorrect values, increasing the likelihood of a runtime failure.\",\n",
      "      \"Thus, not considering **B** logically leads to a high probability of silent runtime errors due to malformed inputs.\"\n",
      "    ],\n",
      "    \"probability\": 0.85\n",
      "  },\n",
      "  \"WeakerErrorHandling\": {\n",
      "    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation typically triggers explicit error‑handling code that raises informative exceptions.\",\n",
      "      \"Without **B**, the developer has no incentive to add an `if not (len(a)==3 and len(b)==3): raise ValueError(...)` block.\",\n",
      "      \"Consequently, failures surface as generic `IndexError` or `TypeError`, reducing clarity for callers and making debugging more difficult.\",\n",
      "      \"Therefore, omitting **B** increases the probability that error handling will be weaker.\"\n",
      "    ],\n",
      "    \"probability\": 0.62\n",
      "  },\n",
      "  \"LessExplicitDocumentationOnInputConstraints\": {\n",
      "    \"description\": \"The docstring would likely omit or downplay the requirement that each input vector contain exactly three elements, reducing maintainability.\",\n",
      "    \"rationale\": [\n",
      "      \"Although **B** does not directly point to **D** (Documentation string), the absence of a concrete validation guard removes a natural reference that would normally be described in the docstring.\",\n",
      "      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, which can be indirectly affected when validation is missing.\",\n",
      "      \"Without a guard, the code lacks a clear statement of input size constraints, leading to a shorter or less detailed docstring.\",\n",
      "      \"Hence, omitting **B** makes weaker documentation on input constraints more probable.\"\n",
      "    ],\n",
      "    \"probability\": 0.48\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "chat_history = []\n",
    "last_response = ''\n",
    "messagges = copy.deepcopy(messages_a)\n",
    "input_file= 'ollama_gpt-oss:latest_step1_step2_sptep3_15.json'\n",
    "introspection_messaages =json.load(open(\"output/introspection/\"+input_file))['scenario_a']['step1']['messages']\n",
    "\n",
    "func, func_name, nodes, factors_message = process_introspection_factors(introspection_messaages)\n",
    "\n",
    "\n",
    "first_node = nodes.pop(0)\n",
    "last_message = {}\n",
    "def run(message, node):\n",
    "    \n",
    "    message['content'] = process_messages(message, func, factors_message, node, None)\n",
    "    print(message['content'])\n",
    "    print(\"-----\")\n",
    "    chat_history.append(message)\n",
    "    last_response = llm.call(messages=chat_history)\n",
    "    #print({'role':'assistant','content':last_response})\n",
    "    print(last_response)\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": last_response})\n",
    "\n",
    "for message in messagges:\n",
    "    last_message = copy.deepcopy(message)\n",
    "    run(message , first_node)\n",
    "\n",
    "while nodes:\n",
    "    print(last_message)\n",
    "    run(last_message, nodes.pop(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dbb1149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I’d love to help you sketch out the causal graph and write counterfactual explanations, but I need to know which variables you’re working with. Could you please list the variables (and any known relationships or constraints) you’d like me to analyze? Once I have that, I can infer the most plausible causal structure and draft the requested counterfactuals.'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variable in the json file ```json\\n{\\n  \"A\": {\\n    \"name\": \"Type hint usage\",\\n    \"description\": \"Adding explicit type hints (Sequence[float], List[float]) clarifies expected inputs and outputs, improving static analysis and developer experience.\",\\n    \"attribution_weight\": 0.20\\n  },\\n  \"B\": {\\n    \"name\": \"Input validation\",\\n    \"description\": \"Checking that both vectors have exactly three elements ensures the function behaves correctly and prevents subtle bugs.\",\\n    \"attribution_weight\": 0.20\\n  },\\n  \"C\": {\\n    \"name\": \"Error handling\",\\n    \"description\": \"Raising a ValueError with a clear message helps callers quickly identify misuse of the API.\",\\n    \"attribution_weight\": 0.15\\n  },\\n  \"D\": {\\n    \"name\": \"Documentation string\",\\n    \"description\": \"A comprehensive docstring (including parameters, returns, and examples) aids readability, IDE assistance, and future maintenance.\",\\n    \"attribution_weight\": 0.15\\n  },\\n  \"E\": {\\n    \"name\": \"Function name\",\\n    \"description\": \"Choosing a concise, descriptive name (cross_product) makes the intent immediately obvious.\",\\n    \"attribution_weight\": 0.10\\n  },\\n  \"F\": {\\n    \"name\": \"Return type\",\\n    \"description\": \"Returning a concrete List[float] rather than a generic Sequence improves usability for callers expecting a mutable sequence.\",\\n    \"attribution_weight\": 0.10\\n  },\\n  \"G\": {\\n    \"name\": \"Code readability\",\\n    \"description\": \"Using clear variable names (a1, a2, a3, etc.) and straightforward arithmetic enhances understandability and maintainability.\",\\n    \"attribution_weight\": 0.10\\n  }\\n}\\n```, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the function cross_product, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Here’s a compact causal graph that shows how the seven design‑choice variables (A–G) influence one another and, ultimately, the generation of the `cross_product` function.  \\nThe graph is written in **Graphviz DOT** syntax and ready to be visualised with any Graphviz‑compatible renderer.\\n\\n```dot\\ndigraph cross_product_causal_graph {\\n  /* Basic styling */\\n  node [shape=box, style=filled, fillcolor=\"#f0f8ff\", fontname=Helvetica];\\n  edge [fontname=Helvetica];\\n\\n  /* Nodes – one per design variable + the code‑generation outcome */\\n  A [label=\"A\\\\nType hint usage\\\\n(0.20)\"];\\n  B [label=\"B\\\\nInput validation\\\\n(0.20)\"];\\n  C [label=\"C\\\\nError handling\\\\n(0.15)\"];\\n  D [label=\"D\\\\nDocumentation string\\\\n(0.15)\"];\\n  E [label=\"E\\\\nFunction name\\\\n(0.10)\"];\\n  F [label=\"F\\\\nReturn type\\\\n(0.10)\"];\\n  G [label=\"G\\\\nCode readability\\\\n(0.10)\"];\\n  CodeGen [label=\"Code Generation\\\\n(cross_product)\"];\\n\\n  /* Core causal links between design choices */\\n  A -> B;      /* Type hints encourage explicit validation */\\n  A -> F;      /* Type hints inform the concrete return type */\\n  B -> C;      /* Validation errors feed into error handling */\\n  D -> G;      /* A rich docstring improves readability */\\n  E -> D;      /* A good name makes the docstring clearer */\\n  F -> G;      /* Return type consistency boosts readability */\\n  F -> D;      /* Concrete return type helps the docstring */\\n  E -> G;      /* A descriptive name aids readability */\\n  D -> C;      /* Documentation may dictate error‑handling style */\\n\\n  /* All variables influence the final code generation */\\n  A -> CodeGen;\\n  B -> CodeGen;\\n  C -> CodeGen;\\n  D -> CodeGen;\\n  E -> CodeGen;\\n  F -> CodeGen;\\n  G -> CodeGen;\\n}\\n```\\n\\n### How to read the graph\\n* **Directed edges (`->`)** represent a causal influence.\\n* For example, the edge `A -> B` means “adding explicit type hints (A) tends to make the author include more thorough input validation (B).”\\n* Each design variable also points directly to **`Code Generation`** because it ultimately contributes to how the `cross_product` function is written.\\n* The weights (in parentheses) are just the attribution scores you supplied; they’re shown in the node labels for reference but don’t alter the causal structure.\\n\\nYou can paste this DOT code into any Graphviz viewer (e.g., `dot -Tpng file.dot -o out.png`) to visualise the causal relationships.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Type hint usage during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing_Input_Validation\": {\\n    \"description\": \"The function would likely be written without checks that both vectors have exactly three elements, increasing the risk of silent errors.\",\\n    \"rationale\": [\\n      \"A (Type hint usage) is a direct cause of B (Input validation).\",\\n      \"Without A, the incentive to add B is weakened, making it more probable that the author skips validation.\",\\n      \"B is also a precursor to C (Error handling). Without B, C may also be omitted, compounding the risk.\",\\n      \"The absence of validation is therefore a direct downstream effect of not considering type hints.\"\\n    ],\\n    \"probability\": 0.75\\n  },\\n  \"Unclear_Return_Type\": {\\n    \"description\": \"The function would return a generic Sequence[float] or even a raw tuple, leading callers to have to cast or convert the result.\",\\n    \"rationale\": [\\n      \"A influences F (Return type) by encouraging a concrete List[float] when type hints are present.\",\\n      \"Without A, the author has no explicit guidance to choose a concrete return type, increasing the chance of a vague or generic type.\",\\n      \"F also affects G (Code readability) and D (Documentation). A missing concrete type can make both documentation and readability poorer.\",\\n      \"Thus, omitting A increases the likelihood of an unclear or generic return type.\"\\n    ],\\n    \"probability\": 0.60\\n  },\\n  \"Lower_Readability_and_Documentation_Quality\": {\\n    \"description\": \"The overall code would be less readable, and the accompanying docstring would be terse or absent, reducing maintainability.\",\\n    \"rationale\": [\\n      \"A affects F, which in turn feeds into G (Code readability).\",\\n      \"F also influences D (Documentation string), which itself influences G.\",\\n      \"E (Function name) and G are also interlinked, so the cascade from missing A can lead to weaker variable naming, fewer explanatory comments, and a shorter docstring.\",\\n      \"The combined loss of type hints, clear return type, and validation reduces the motivation to write clean, well‑documented code.\"\\n    ],\\n    \"probability\": 0.45\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing_Input_Validation_Leads_to_Runtime_Errors\": {\\n    \"description\": \"Without the explicit input validation step, the function would accept vectors of any length, increasing the likelihood of silent runtime failures or incorrect calculations.\",\\n    \"rationale\": [\\n      \"In the causal graph, the node **B** (Input validation) directly influences **Code Generation** via the edge B\\xa0→\\xa0CodeGen, meaning validation is a core part of the final function.\",\\n      \"Because **B** is absent, the guard that ensures each vector has exactly three elements is omitted, leaving the arithmetic expressions in the function body exposed to unexpected shapes.\",\\n      \"This omission directly raises the probability of runtime errors such as index‑out‑of‑range or dimensionality mismatches when the function is invoked with malformed inputs.\",\\n      \"The graph also shows that **B** → **C** (Error handling); without validation, the error‑handling logic that could catch and report such problems is less likely to be written.\",\\n      \"Therefore, the absence of **B** logically leads to a higher chance of silent runtime failures.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"Reduced_Error_Handling_Robustness\": {\\n    \"description\": \"The lack of input validation weakens the error‑handling strategy, so the function may propagate misleading exceptions or fail silently.\",\\n    \"rationale\": [\\n      \"Edge **B** → **C** in the graph indicates that validation triggers the inclusion of appropriate error handling logic.\",\\n      \"When **B** is omitted, the developer has no incentive to add checks that raise informative ValueErrors or guard against unexpected inputs.\",\\n      \"Consequently, the function may rely on low‑level Python errors (e.g., IndexError, TypeError) that provide little context to callers.\",\\n      \"This causal chain (B absence → C absence) yields a moderate‑to‑high probability that error handling will be less robust.\"\\n    ],\\n    \"probability\": 0.65\\n  },\\n  \"Weaker_Documentation_on_Input_Constraints\": {\\n    \"description\": \"Documentation may become terse or omit explicit size constraints for the input vectors, reducing code maintainability.\",\\n    \"rationale\": [\\n      \"The graph contains an edge **D** → **G** (Documentation → Readability) and **F** → **D** (Return type → Documentation).\",\\n      \"While **B** does not directly influence **D**, a missing validation step reduces the need for the docstring to describe input constraints, leading to a shorter or less detailed documentation block.\",\\n      \"The absence of explicit checks in the code also decreases the motivation to document such checks, creating a subtle feedback loop where less validation leads to less documentation.\",\\n      \"Thus, the causal structure supports the notion that omitting **B** increases the likelihood of weaker documentation.\"\\n    ],\\n    \"probability\": 0.45\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"RuntimeFailuresFromUndeclaredVectorLengths\": {\\n    \"description\": \"Without input validation, the function would accept vectors of any length, which could lead to silent runtime failures (e.g., IndexError or incorrect cross‑product values).\",\\n    \"rationale\": [\\n      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (B → CodeGen), meaning validation is an essential part of the final function body.\",\\n      \"Removing **B** eliminates the guard that checks `len(a) == 3 and len(b) == 3`, leaving the arithmetic expressions vulnerable to malformed inputs.\",\\n      \"Because the code would then compute `a[0]*b[1] - a[1]*b[0]` etc. without verifying indices, a vector of length <\\u202f3 would raise an IndexError or produce incorrect results.\",\\n      \"Thus the absence of **B** logically increases the probability of runtime failures due to unexpected vector sizes.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"DiminishedError‑HandlingRobustness\": {\\n    \"description\": \"The function would rely on generic Python exceptions instead of clear `ValueError` messages, making it harder for callers to diagnose misuse.\",\\n    \"rationale\": [\\n      \"The graph contains the edge **B** → **C** (Input validation → Error handling). Validation typically triggers explicit error‑handling code that raises informative exceptions.\",\\n      \"If **B** is omitted, the developer has less motivation to write the `if not (len(a) == 3 and len(b) == 3): raise ValueError(...)` block, and the function may fail silently or surface low‑level errors.\",\\n      \"Consequently, the error‑handling path is weaker, reducing the clarity of failure modes.\"\\n    ],\\n    \"probability\": 0.65\\n  },\\n  \"LessExplicitDocumentationOnInputConstraints\": {\\n    \"description\": \"The docstring would likely omit or gloss over the requirement that each vector contain exactly three elements, lowering maintainability.\",\\n    \"rationale\": [\\n      \"While **B** does not directly point to **D** (Documentation string) in the graph, the absence of explicit validation reduces the incentive to document input constraints.\",\\n      \"Edges **D** → **G** and **F** → **D** show that documentation quality feeds into readability and is influenced by return‑type decisions. Without validation, the code lacks a concrete check that would naturally be described in the docstring.\",\\n      \"Therefore, the causal structure suggests a higher chance that the documentation will be less detailed regarding input size.\"\\n    ],\\n    \"probability\": 0.45\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"RuntimeFailureDueToMissingValidation\": {\\n    \"description\": \"The function would accept vectors of any length, leading to silent runtime errors or incorrect cross‑product results.\",\\n    \"rationale\": [\\n      \"The causal graph shows an edge B → CodeGen, meaning input validation directly shapes the generated code.\",\\n      \"Without B, the guard `len(a) == 3 and len(b) == 3` is omitted, leaving arithmetic expressions that assume three elements.\",\\n      \"When a vector of length <\\u202f3 is passed, the code will raise an IndexError or compute wrong values, thus increasing failure probability.\",\\n      \"Therefore, omitting B logically raises the chance of runtime failures caused by malformed inputs.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"ReducedErrorHandlingRobustness\": {\\n    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\\n    \"rationale\": [\\n      \"The graph contains the edge B → C (Input validation → Error handling).\",\\n      \"When B is absent, the developer has no explicit trigger to add an error‑handling block that raises informative exceptions.\",\\n      \"Consequently, failures would surface as generic IndexError or TypeError, reducing clarity for callers.\",\\n      \"Thus, omitting B increases the likelihood of weaker error handling.\"\\n    ],\\n    \"probability\": 0.65\\n  },\\n  \"WeakInputConstraintsDocumentation\": {\\n    \"description\": \"The docstring would likely omit or understate the requirement that each input vector contains exactly three elements, reducing maintainability.\",\\n    \"rationale\": [\\n      \"Although B does not directly point to D (Documentation), the absence of explicit validation decreases the motivation to document input size constraints.\",\\n      \"Edges D → G and F → D show that documentation quality is tied to return type and readability, which are indirectly affected by missing validation.\",\\n      \"Without a validation guard, the code lacks a concrete check that would naturally be referenced in the docstring, leading to less detailed documentation.\",\\n      \"Therefore, not considering B makes weaker documentation on input constraints more probable.\"\\n    ],\\n    \"probability\": 0.45\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"RuntimeFailureDueToMissingValidation\": {\\n    \"description\": \"The function would accept vectors of any length, leading to silent runtime errors or incorrect cross‑product results.\",\\n    \"rationale\": [\\n      \"In the causal graph, **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This means the validation guard is part of the final code.\",\\n      \"Without **B**, the guard `if len(a) != 3 or len(b) != 3: raise ValueError(...)` would be omitted, leaving the arithmetic expressions to assume three elements.\",\\n      \"When a vector of length <\\u202f3 is passed, the code will raise an `IndexError` or produce mathematically incorrect values, so the probability of runtime failure increases dramatically.\",\\n      \"Thus, the absence of **B** logically leads to a high chance of silent runtime failures caused by malformed inputs.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"ReducedErrorHandlingRobustness\": {\\n    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\\n    \"rationale\": [\\n      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation usually triggers explicit error‑handling code that raises informative exceptions.\",\\n      \"If **B** is omitted, the developer has no explicit trigger to add an error‑handling block that raises `ValueError` with a descriptive message.\",\\n      \"Consequently, failures would surface as generic `IndexError` or `TypeError`, reducing clarity for callers and making debugging more difficult.\",\\n      \"Hence, not considering **B** increases the probability that error handling will be weaker.\"\\n    ],\\n    \"probability\": 0.62\\n  },\\n  \"WeakerDocumentationOnInputConstraints\": {\\n    \"description\": \"The docstring would likely omit or understate the requirement that each input vector contains exactly three elements, reducing maintainability.\",\\n    \"rationale\": [\\n      \"Although **B** does not directly point to **D** (Documentation string), the absence of explicit validation removes a concrete check that would normally be described in the docstring.\",\\n      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, which are indirectly affected when validation is missing.\",\\n      \"Without a validation guard, the code lacks a clear point of reference for documenting input size constraints, leading to less detailed or absent documentation.\",\\n      \"Thus, omitting **B** makes weaker documentation on input constraints more probable.\"\\n    ],\\n    \"probability\": 0.48\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"MissingValidationCausesRuntimeErrors\": {\\n    \"description\": \"Without an explicit validation guard, the function will accept vectors of any length, leading to silent IndexErrors or mathematically incorrect results.\",\\n    \"rationale\": [\\n      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This means that the guard that checks `len(a) == 3 and len(b) == 3` is part of the generated code.\",\\n      \"If **B** is omitted, the guard is missing. The arithmetic expressions (`a[0]*b[1] - a[1]*b[0]`, etc.) assume three elements and will fail or produce wrong values when the inputs are shorter.\",\\n      \"Because the function can now be called with malformed inputs, the probability that a runtime failure occurs rises sharply.\",\\n      \"Thus the absence of **B** logically leads to a high chance of runtime errors caused by unexpected vector sizes.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"WeakErrorHandling\": {\\n    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\\n    \"rationale\": [\\n      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation normally triggers explicit error‑handling code that raises informative exceptions.\",\\n      \"When **B** is omitted, there is no incentive to add an `if not (len(a)==3 and len(b)==3): raise ValueError(...)` block. The code would fail with generic `IndexError` or `TypeError` instead.\",\\n      \"Consequently, callers receive less contextual information and debugging becomes more difficult.\",\\n      \"Therefore, not considering **B** increases the probability that error handling will be weaker.\"\\n    ],\\n    \"probability\": 0.62\\n  },\\n  \"InadequateDocumentationOnInputConstraints\": {\\n    \"description\": \"The docstring would likely omit or downplay the requirement that each vector contain exactly three elements, reducing maintainability.\",\\n    \"rationale\": [\\n      \"Although **B** does not directly point to **D** (Documentation string), the absence of a concrete validation guard removes a natural point of reference that would normally be described in the docstring.\",\\n      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, both of which can be affected indirectly when validation is missing.\",\\n      \"Without a guard, the code lacks a clear statement of input size constraints, leading to a shorter or less detailed docstring.\",\\n      \"Hence, omitting **B** makes weaker documentation on input constraints more probable.\"\\n    ],\\n    \"probability\": 0.48\\n  }\\n}\\n```\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Input validation during the generation of the cross_product function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '{\\n  \"RuntimeFailureDueToMissingValidation\": {\\n    \"description\": \"The function would accept vectors of any length, causing silent IndexErrors or mathematically incorrect cross‑product results.\",\\n    \"rationale\": [\\n      \"In the causal graph, node **B** (Input validation) has a direct edge to **CodeGen** (`B -> CodeGen`). This edge represents the inclusion of a validation guard in the generated code.\",\\n      \"When **B** is omitted, the guard `if len(a) != 3 or len(b) != 3: raise ValueError(...)` is missing, leaving the arithmetic expressions (`a[0]*b[1] - a[1]*b[0]`, etc.) to assume three elements.\",\\n      \"If the function is called with a vector of length <\\u202f3, an `IndexError` will be raised or the computation will produce incorrect values, increasing the likelihood of a runtime failure.\",\\n      \"Thus, not considering **B** logically leads to a high probability of silent runtime errors due to malformed inputs.\"\\n    ],\\n    \"probability\": 0.85\\n  },\\n  \"WeakerErrorHandling\": {\\n    \"description\": \"The function would rely on low‑level Python exceptions instead of clear `ValueError` messages, making misuse harder to diagnose.\",\\n    \"rationale\": [\\n      \"The graph contains the edge `B -> C` (Input validation → Error handling). Validation typically triggers explicit error‑handling code that raises informative exceptions.\",\\n      \"Without **B**, the developer has no incentive to add an `if not (len(a)==3 and len(b)==3): raise ValueError(...)` block.\",\\n      \"Consequently, failures surface as generic `IndexError` or `TypeError`, reducing clarity for callers and making debugging more difficult.\",\\n      \"Therefore, omitting **B** increases the probability that error handling will be weaker.\"\\n    ],\\n    \"probability\": 0.62\\n  },\\n  \"LessExplicitDocumentationOnInputConstraints\": {\\n    \"description\": \"The docstring would likely omit or downplay the requirement that each input vector contain exactly three elements, reducing maintainability.\",\\n    \"rationale\": [\\n      \"Although **B** does not directly point to **D** (Documentation string), the absence of a concrete validation guard removes a natural reference that would normally be described in the docstring.\",\\n      \"Edges `D -> G` (Documentation → Readability) and `F -> D` (Return type → Documentation) show that documentation quality is tied to return type and readability, which can be indirectly affected when validation is missing.\",\\n      \"Without a guard, the code lacks a clear statement of input size constraints, leading to a shorter or less detailed docstring.\",\\n      \"Hence, omitting **B** makes weaker documentation on input constraints more probable.\"\\n    ],\\n    \"probability\": 0.48\\n  }\\n}'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ca2128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variable in the json file {FACTORS}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the function {FUNCTION}, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the {FUNCTION} function? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "125e68b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell run number is: 18\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "# Get the current execution count\n",
    "exec_count = get_ipython().execution_count\n",
    "print(\"This cell run number is:\", exec_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1598a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\n",
    "    'scenario_a': {\n",
    "        'step1': {'messages': chat_history}\n",
    "    }\n",
    "}\n",
    "file = \"output/interpretability/\"+ llm.model.replace(\"/\",\"_\")+\"_step1_\"+ str(exec_count) +\".json\"\n",
    "with open(file, \"w\") as f:\n",
    "    json.dump(output, f, indent=4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04d3a5",
   "metadata": {},
   "source": [
    "# Scenario A - interpretability - step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18086d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_2 = causal_template['scenario_a']['step2']['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2eb2bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variables in the json file {FACTORS}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the test case {TEST}, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f779f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m ready to help you build the causal graph and draft counterfactual explanations, but I’ll need a bit more detail to get started. Specifically:\n",
      "\n",
      "1. **List of Variables** – What are the observed variables (e.g., X₁, X₂, … Xₙ)?  \n",
      "2. **Domain Context** – A short description of the problem setting (e.g., clinical study, marketing campaign, economic policy).  \n",
      "3. **Data Availability** – Do you have observational data, experimental data, or both?  \n",
      "4. **Any Prior Knowledge** – Known causal relationships or constraints (e.g., “age” cannot be caused by “income”).  \n",
      "5. **Goal of Counterfactuals** – What kind of counterfactual questions do you want to answer? (e.g., “What if patient A had received drug B?”)\n",
      "\n",
      "Once I have this information, I can:\n",
      "\n",
      "- Sketch a plausible directed acyclic graph (DAG) or structural causal model (SCM).  \n",
      "- Discuss identification assumptions (confounding, back‑door paths, instrumental variables, etc.).  \n",
      "- Provide a step‑by‑step construction of counterfactuals using the SCM (e.g., *do*‑interventions, “counterfactual worlds”).  \n",
      "- Generate example counterfactual explanations tailored to your variables.\n",
      "\n",
      "Feel free to share the variables and context, and we’ll build the causal story together!\n",
      "[CAUSAL TASK] Giving the following variables in the json file {\n",
      "  \"A\": {\n",
      "    \"name\": \"Function Complexity\",\n",
      "    \"description\": \"The number of logical branches, nested conditions, and overall algorithmic complexity of the function.\",\n",
      "    \"weight\": 0.25\n",
      "  },\n",
      "  \"B\": {\n",
      "    \"name\": \"Input Validation\",\n",
      "    \"description\": \"Whether the function checks the validity of its inputs (e.g., length, type, value ranges).\",\n",
      "    \"weight\": 0.20\n",
      "  },\n",
      "  \"C\": {\n",
      "    \"name\": \"Error Handling\",\n",
      "    \"description\": \"The presence and robustness of error handling logic, such as raising exceptions for invalid cases.\",\n",
      "    \"weight\": 0.15\n",
      "  },\n",
      "  \"D\": {\n",
      "    \"name\": \"Dependencies\",\n",
      "    \"description\": \"External modules, services, or global state that the function relies on, influencing isolation in tests.\",\n",
      "    \"weight\": 0.10\n",
      "  },\n",
      "  \"E\": {\n",
      "    \"name\": \"Documentation/Contract\",\n",
      "    \"description\": \"Clarity of the function's docstring, parameter and return type contracts, and adherence to specifications.\",\n",
      "    \"weight\": 0.15\n",
      "  },\n",
      "  \"F\": {\n",
      "    \"name\": \"Edge Cases\",\n",
      "    \"description\": \"The likelihood of encountering unusual or boundary inputs that could reveal hidden bugs.\",\n",
      "    \"weight\": 0.15\n",
      "  }\n",
      "}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the test case import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main(), therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.\n",
      "-----\n",
      "Here is a directed acyclic graph (DAG) in Graphviz **DOT** format that captures the causal relationships among the six code‑quality variables, the generation of the test case, and the final code‑generation node.  \n",
      "\n",
      "```dot\n",
      "digraph CausalGraph {\n",
      "    // Node shape and common styling\n",
      "    node [shape=box, style=filled, fillcolor=lightgrey, fontname=Helvetica, fontsize=10];\n",
      "\n",
      "    // Variables\n",
      "    A [label=\"A\\nFunction Complexity\"];\n",
      "    B [label=\"B\\nInput Validation\"];\n",
      "    C [label=\"C\\nError Handling\"];\n",
      "    D [label=\"D\\nDependencies\"];\n",
      "    E [label=\"E\\nDocumentation/Contract\"];\n",
      "    F [label=\"F\\nEdge Cases\"];\n",
      "\n",
      "    // Down‑stream processes\n",
      "    G [label=\"G\\nTest Case Generation\", fillcolor=lightblue];\n",
      "    H [label=\"H\\nCode Generation\", fillcolor=lightgreen];\n",
      "\n",
      "    // 1️⃣ Causal influence among quality attributes\n",
      "    A -> B;          // Complex functions usually need more validation\n",
      "    A -> C;          // Complex logic demands robust error handling\n",
      "    A -> D;          // More complex code tends to use more dependencies\n",
      "    B -> C;          // Validation failures trigger error handling\n",
      "    B -> F;          // Good validation uncovers edge cases\n",
      "    C -> D;          // Error‑handling wrappers may pull in external modules\n",
      "    C -> F;          // Proper error handling exposes hidden edge cases\n",
      "    D -> E;          // External dependencies must be documented\n",
      "    E -> F;          // Clear docs/contract help identify edge cases\n",
      "\n",
      "    // 2️⃣ Influence on test‑case generation\n",
      "    A -> G;\n",
      "    B -> G;\n",
      "    C -> G;\n",
      "    D -> G;\n",
      "    E -> G;\n",
      "    F -> G;\n",
      "\n",
      "    // 3️⃣ Influence on code generation (separate node)\n",
      "    G -> H;          // The test‑case generator drives the final code output\n",
      "}\n",
      "```\n",
      "\n",
      "### Quick Interpretation\n",
      "\n",
      "| Edge | Causal Path |\n",
      "|------|-------------|\n",
      "| `A → B, C, D` | Complexity drives validation, error handling, and dependency use. |\n",
      "| `B → C, F` | Validation informs error handling and surfaces edge cases. |\n",
      "| `C → D, F` | Error handling can introduce dependencies and reveal edge cases. |\n",
      "| `D → E` | Dependencies must be documented. |\n",
      "| `E → F` | Documentation clarifies contract and surfaces edge cases. |\n",
      "| `A–F → G` | All quality factors feed into the test‑case generation process. |\n",
      "| `G → H` | Generated tests inform the final code‑generation step. |\n",
      "\n",
      "Feel free to paste the DOT snippet into any Graphviz‑compatible renderer (e.g., `dot -Tpng file.dot -o graph.png`) to visualise the causal graph.\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Function Complexity during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missed Complex Edge Cases\": {\n",
      "    \"description\": \"Test cases that would have been generated to exercise deep logical branches and nested conditions were omitted.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Function Complexity (A) directly feeds into Test‑Case Generation (G).\",\n",
      "      \"Because A also drives Input Validation (B), Error Handling (C), and Dependencies (D), the absence of A removes the trigger for generating tests that cover multi‑branch logic, nested conditions, and edge‑case propagation.\",\n",
      "      \"Without these tests, subtle bugs that only appear when the function processes complex inputs can slip through.\",\n",
      "      \"Thus, the probability of such a failure scenario is relatively high due to the strong 0.25 weight on A and its direct G link.\"\n",
      "    ],\n",
      "    \"probability\": 0.40\n",
      "  },\n",
      "  \"Incomplete Dependency Coverage\": {\n",
      "    \"description\": \"Tests that verify interactions with external modules or global state were missing, potentially leading to runtime errors.\",\n",
      "    \"rationale\": [\n",
      "      \"Function Complexity influences Dependencies (D) (edge A → D).\",\n",
      "      \"Dependencies in turn affect Documentation/Contract (E) and Edge Cases (F) before reaching G.\",\n",
      "      \"Without A, the tester’s focus on D diminishes, so the test generator is less likely to create scenarios that exercise external interactions.\",\n",
      "      \"This indirect path, while weaker (weight 0.10 for D), still contributes a moderate chance of oversight.\"\n",
      "    ],\n",
      "    \"probability\": 0.25\n",
      "  },\n",
      "  \"Overall Impact Minimal\": {\n",
      "    \"description\": \"The test suite remains largely adequate because other quality attributes (B, C, D, E, F) still guide test creation.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph shows that B, C, D, E, and F all have direct edges to G.\",\n",
      "      \"Even without A, these variables can produce a reasonably comprehensive set of tests (e.g., validation, error handling, documentation checks).\",\n",
      "      \"Therefore, there is a non‑negligible but lower probability that omitting A does not noticeably degrade the test coverage.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Input Validation during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing Invalid‑Input Tests\": {\n",
      "    \"description\": \"Test cases that assert a `ValueError` for vectors not of length three would be omitted.\",\n",
      "    \"rationale\": [\n",
      "      \"Input Validation (B) has a direct causal edge to Test‑Case Generation (G); without B, the generator has no trigger to create length‑check tests.\",\n",
      "      \"B also feeds into Error Handling (C).  If B is ignored, C receives no input‑validation signal, so the error‑handling logic may not be exercised in the suite.\",\n",
      "      \"The weight of B is 0.20, and the path B→G accounts for a substantial portion of G’s total causal input.  Removing it reduces the probability that length‑check tests are produced.\",\n",
      "      \"Consequently, the likelihood of failing to cover the `ValueError` scenario rises.\"\n",
      "    ],\n",
      "    \"probability\": 0.30\n",
      "  },\n",
      "\n",
      "  \"Reduced Edge‑Case Coverage\": {\n",
      "    \"description\": \"The test suite would miss scenarios that probe unusual or boundary inputs, such as empty lists or non‑sequence types.\",\n",
      "    \"rationale\": [\n",
      "      \"B has a direct influence on Edge Cases (F) (B→F).  Edge Cases subsequently feed into G, so when B is ignored, F receives a weaker signal.\",\n",
      "      \"The indirect chain B→F→G explains why boundary‑condition tests are less likely to be generated.\",\n",
      "      \"Because F’s weight is 0.15 and its path through G is part of the overall test‑generation mechanism, omitting B lowers the probability of edge‑case tests by roughly 0.15–0.20.\",\n",
      "      \"Thus, the chance that the test suite fails to cover boundary conditions increases.\"\n",
      "    ],\n",
      "    \"probability\": 0.25\n",
      "  },\n",
      "\n",
      "  \"Weaker Error‑Handling Assertions\": {\n",
      "    \"description\": \"Assertions that confirm the function raises the correct exception types (e.g., `ValueError`, `TypeError`) would be under‑represented.\",\n",
      "    \"rationale\": [\n",
      "      \"B’s influence on Error Handling (C) (B→C) means that, without considering B, C receives no explicit push to test error paths.\",\n",
      "      \"C also feeds into G (C→G).  The combined loss of B→C and C→G edges reduces the overall likelihood that error‑handling checks are included.\",\n",
      "      \"Given the weight of C (0.15) and its contribution to G, the probability that these assertions are omitted is estimated at about 0.20.\",\n",
      "      \"This increases the risk that runtime exceptions slip through untested.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Error Handling during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing Exception Assertion Tests\": {\n",
      "    \"description\": \"Test cases that explicitly verify the function raises `ValueError` for non‑length‑3 vectors or `TypeError` for non‑sequence inputs would be omitted.\",\n",
      "    \"rationale\": [\n",
      "      \"In the DAG, Error Handling (C) has a direct causal edge to Test‑Case Generation (G) (C → G).\",\n",
      "      \"When the tester ignores C, the generator has no trigger to create the `assertRaises(ValueError/TypeError)` assertions that are already present in the supplied test suite.\",\n",
      "      \"C also drives Error Handling logic in the code; without considering C, the tester fails to probe that code path.\",\n",
      "      \"Because C carries a weight of 0.15 and accounts for a significant share of the overall input to G, the probability that such exception‑handling tests are missing rises to roughly 35 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.35\n",
      "  },\n",
      "\n",
      "  \"Reduced Dependency‑Interaction Coverage\": {\n",
      "    \"description\": \"Tests that validate how the function behaves when it interacts with external modules or global state (e.g., through dependency injection or mocking) would be less likely to appear.\",\n",
      "    \"rationale\": [\n",
      "      \"Error Handling influences Dependencies via the edge C → D.  Without C, the signal to include dependency‑wrapping tests is weakened.\",\n",
      "      \"Dependencies (D) then affect Documentation/Contract (E) and Edge Cases (F), which in turn feed into G.  Thus, the indirect path C → D → G is broken.\",\n",
      "      \"Since D has a weight of 0.10 and the indirect contribution to G is modest, the probability of missing dependency‑interaction tests is estimated at about 20 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  },\n",
      "\n",
      "  \"Diminished Edge‑Case Detection\": {\n",
      "    \"description\": \"Boundary and unusual input scenarios (empty lists, non‑sequence types, etc.) would receive less coverage in the generated tests.\",\n",
      "    \"rationale\": [\n",
      "      \"C contributes to Edge Cases through C → F.  Ignoring C removes that input signal to F.\",\n",
      "      \"Edge Cases (F) have a direct edge to G, so the absence of C reduces the overall weight that F can provide to test‑generation.\",\n",
      "      \"Given F’s weight of 0.15, the loss of its contribution to G translates to an approximate 25 % chance that edge‑case tests are omitted.\"\n",
      "    ],\n",
      "    \"probability\": 0.25\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Dependencies during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing Dependency‑Interaction Tests\": {\n",
      "    \"description\": \"Test cases that would validate the function’s interaction with external modules or global state (e.g., mock‑ing a vector source or ensuring isolation from shared resources) would not be generated.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Dependencies (D) have a direct edge to Test‑Case Generation (G) (D → G).\",\n",
      "      \"When the tester ignores D, the generator lacks the trigger to create scenarios that exercise external dependencies or mock‑based setups.\",\n",
      "      \"Although D’s weight is 0.10, the edge D → G accounts for a non‑negligible share of the causal influence on G; thus, omission raises the probability that such tests are missing.\",\n",
      "      \"Given the moderate weight of D relative to other factors, we estimate this omission occurs about 22 % of the time.\"\n",
      "    ],\n",
      "    \"probability\": 0.22\n",
      "  },\n",
      "  \"Reduced Documentation/Contract Coverage\": {\n",
      "    \"description\": \"Tests that confirm the function’s public contract (type hints, docstring correctness, and dependency‑related specifications) would be under‑represented.\",\n",
      "    \"rationale\": [\n",
      "      \"Dependencies influence Documentation/Contract through the edge D → E.  E, in turn, feeds into Test‑Case Generation (E → G).\",\n",
      "      \"If D is ignored, the signal to E is weakened, leading to fewer contract‑related assertions in the suite.\",\n",
      "      \"The indirect path D → E → G is shorter and carries the 0.10 weight of D, suggesting a lower but still noticeable risk of missing such tests.\",\n",
      "      \"We approximate the probability of this effect at around 13 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.13\n",
      "  },\n",
      "  \"Diminished Edge‑Case Detection\": {\n",
      "    \"description\": \"Boundary or unusual input scenarios (e.g., empty vectors, non‑sequence arguments) would receive less coverage in the generated tests.\",\n",
      "    \"rationale\": [\n",
      "      \"Dependencies influence Edge Cases via the chain D → E → F (since E → F is present).  Edge Cases (F) has a direct edge to G.\",\n",
      "      \"Without considering D, the chain that feeds F is weakened, reducing the weight that F can contribute to G.\",\n",
      "      \"Given F’s weight of 0.15 and the indirect contribution from D, the chance of missing edge‑case tests is roughly 18 %.\",\n",
      "      \"Thus, the probability that boundary‑condition checks are omitted is estimated at 0.18.\"\n",
      "    ],\n",
      "    \"probability\": 0.18\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Documentation/Contract during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing Contract‑Verification Tests\": {\n",
      "    \"description\": \"Assertions that explicitly confirm the public contract of `cross_product` (e.g., correct type hints, docstring wording, and declared dependencies) would not be generated.\",\n",
      "    \"rationale\": [\n",
      "      \"Documentation/Contract (E) has a direct causal edge to Test‑Case Generation (G) – E → G.  Ignoring E removes this trigger.\",\n",
      "      \"All tests that validate the function’s signature or docstring are therefore absent from the automatically generated suite.\",\n",
      "      \"E carries a weight of 0.15, which constitutes a non‑trivial share of the total causal influence on G (in addition to the direct E → G edge).\",\n",
      "      \"Given this moderate weight, we estimate that contract‑verification tests are omitted with a probability of about 0.18.\"\n",
      "    ],\n",
      "    \"probability\": 0.18\n",
      "  },\n",
      "\n",
      "  \"Reduced Edge‑Case Coverage via Documentation\": {\n",
      "    \"description\": \"Boundary or unusual input scenarios (e.g., empty vectors, non‑sequence arguments) would receive less coverage in the generated tests.\",\n",
      "    \"rationale\": [\n",
      "      \"E influences Edge Cases (F) through the chain E → F.  Edge Cases then feed into G via F → G.\",\n",
      "      \"Without considering Documentation/Contract, the signal that drives F is weakened, so F contributes less weight to G.\",\n",
      "      \"F has a weight of 0.15, but the indirect contribution from E is only 0.15 × 0.15 ≈ 0.0225 of the total G input.\",\n",
      "      \"This loss translates to an estimated 12 % chance that edge‑case tests are omitted.\"\n",
      "    ],\n",
      "    \"probability\": 0.12\n",
      "  },\n",
      "\n",
      "  \"Diminished Dependency‑Contract Tests\": {\n",
      "    \"description\": \"Tests that confirm how external dependencies are documented and used (e.g., parameter contracts for injected vector sources) would be under‑represented.\",\n",
      "    \"rationale\": [\n",
      "      \"Dependencies (D) influence Documentation/Contract via D → E.  Ignoring E weakens the signal from D to E.\",\n",
      "      \"E also feeds into Test‑Case Generation (E → G).  Thus the indirect path D → E → G is broken when E is omitted.\",\n",
      "      \"The weight of D is 0.10, and its indirect contribution to G through E is modest, suggesting a lower but still noticeable risk.\",\n",
      "      \"We approximate the probability of missing such dependency‑contract tests at about 0.09.\"\n",
      "    ],\n",
      "    \"probability\": 0.09\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable {NODE} during the generation of the {TEST} test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Edge Cases during the generation of the import unittest\n",
      "from typing import Sequence, List\n",
      "\n",
      "def cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\n",
      "    \"\"\"\n",
      "    Compute the cross product of two 3‑D vectors.\n",
      "    \"\"\"\n",
      "    if len(a) != 3 or len(b) != 3:\n",
      "        raise ValueError(\"Both vectors must be of length 3.\")\n",
      "    a1, a2, a3 = a\n",
      "    b1, b2, b3 = b\n",
      "    return [\n",
      "        a2 * b3 - a3 * b2,\n",
      "        a3 * b1 - a1 * b3,\n",
      "        a1 * b2 - a2 * b1,\n",
      "    ]\n",
      "\n",
      "class TestCrossProduct(unittest.TestCase):\n",
      "    def test_basic_cross_product(self):\n",
      "        a = [1, 2, 3]\n",
      "        b = [4, 5, 6]\n",
      "        expected = [-3, 6, -3]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_with_zero_vector(self):\n",
      "        a = [0, 0, 0]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_orthogonal_vectors(self):\n",
      "        a = [1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, 1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_parallel_vectors(self):\n",
      "        a = [2, 4, 6]\n",
      "        b = [1, 2, 3]\n",
      "        expected = [0, 0, 0]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_negative_vector(self):\n",
      "        a = [-1, 0, 0]\n",
      "        b = [0, 1, 0]\n",
      "        expected = [0, 0, -1]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertEqual(result, expected)\n",
      "\n",
      "    def test_cross_product_return_type(self):\n",
      "        a = (1, 2, 3)\n",
      "        b = [4, 5, 6]\n",
      "        result = cross_product(a, b)\n",
      "        self.assertIsInstance(result, list)\n",
      "        self.assertEqual(len(result), 3)\n",
      "\n",
      "    def test_cross_product_invalid_length(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2], [3, 4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([1, 2, 3], [4, 5])\n",
      "        with self.assertRaises(ValueError):\n",
      "            cross_product([], [])\n",
      "\n",
      "    def test_cross_product_non_sequence_inputs(self):\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product([1, 2, 3], None)\n",
      "        with self.assertRaises(TypeError):\n",
      "            cross_product(None, [1, 2, 3])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Missing Extreme‑Value Edge‑Case Tests\": {\n",
      "    \"description\": \"Test cases that would probe how `cross_product` handles extreme or special numeric inputs (e.g., `float('nan')`, `float('inf')`, extremely large or small numbers) would not be generated.\",\n",
      "    \"rationale\": [\n",
      "      \"In the DAG, Edge Cases (F) have a direct causal edge to Test‑Case Generation (G) – F → G.  Ignoring F removes this trigger.\",\n",
      "      \"The weight attached to F is 0.15, representing a non‑trivial share of the total causal influence on G.\",\n",
      "      \"Consequently, the probability that the automatically generated test suite lacks tests for extreme numeric values is approximately the weight of F, i.e. about 15 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.15\n",
      "  },\n",
      "  \"Reduced Boundary‑Vector‑Length Coverage\": {\n",
      "    \"description\": \"Tests that cover boundary conditions for vector lengths (e.g., vectors of length 0, 1, or 2, and vectors that are exactly the minimum or maximum allowed size) would be under‑represented.\",\n",
      "    \"rationale\": [\n",
      "      \"Boundary‑length checks are a subset of the Edge‑Case domain.  Since Edge Cases influence Test‑Case Generation via F → G, ignoring F suppresses all edge‑case–related length tests.\",\n",
      "      \"A conservative estimate for missing such tests is slightly lower than the overall F weight because a portion of the boundary checks might also be generated by the Input‑Validation sub‑branch.  We therefore approximate the missing‑test probability at ~12 %.\",\n",
      "      \"Thus, the likelihood that the test suite fails to include length‑boundary tests is roughly 12 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.12\n",
      "  },\n",
      "  \"Lack of Tests for Invalid Argument Types Beyond `None`\": {\n",
      "    \"description\": \"The suite would miss scenarios where non‑sequence types (e.g., `int`, `float`, `dict`, `list` of non‑numeric elements) are passed to `cross_product`—tests that are normally produced by Edge Cases.\",\n",
      "    \"rationale\": [\n",
      "      \"Type‑related edge‑case tests are also governed by Edge Cases.  When F is ignored, the generator does not produce these tests.\",\n",
      "      \"Given the Edge‑Case weight of 0.15, the chance of omitting such type‑boundary tests is somewhat lower because a few of them might still be triggered by Exception Handling or Input Validation; an estimate of about 8 % captures this reduced overlap.\",\n",
      "      \"Hence, the probability that the generated suite lacks type‑boundary tests beyond the already present `None` checks is around 8 %.\"\n",
      "    ],\n",
      "    \"probability\": 0.08\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "chat_history_2 = []\n",
    "last_response = ''\n",
    "messagges = copy.deepcopy(messages_2)\n",
    "input_file= 'ollama_gpt-oss:latest_step1_step2_sptep3_15.json'\n",
    "introspection_messaages =json.load(open(\"output/introspection/\"+input_file))['scenario_a']['step2']['messages']\n",
    "\n",
    "func_name, func, nodes, factors_message = process_introspection_factors(introspection_messaages)\n",
    "\n",
    "\n",
    "first_node = nodes.pop(0)\n",
    "last_message = {}\n",
    "def run(message, node):\n",
    "    \n",
    "    message['content'] = process_messages(message, None, factors_message, node, func)\n",
    "    print(message['content'])\n",
    "    print(\"-----\")\n",
    "    chat_history_2.append(message)\n",
    "    last_response = llm.call(messages=chat_history_2)\n",
    "    #print({'role':'assistant','content':last_response})\n",
    "    print(last_response)\n",
    "    chat_history_2.append({\"role\": \"assistant\", \"content\": last_response})\n",
    "\n",
    "for message in messagges:\n",
    "    last_message = copy.deepcopy(message)\n",
    "    run(message , first_node)\n",
    "\n",
    "while nodes:\n",
    "    print(last_message)\n",
    "    run(copy.deepcopy(last_message), nodes.pop(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0dc0f",
   "metadata": {},
   "source": [
    "chat_history_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e4963aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I’m ready to help you build the causal graph and draft counterfactual explanations, but I’ll need a bit more detail to get started. Specifically:\\n\\n1. **List of Variables** – What are the observed variables (e.g.,\\u202fX₁,\\u202fX₂,\\u202f…\\u202fXₙ)?  \\n2. **Domain Context** – A short description of the problem setting (e.g.,\\u202fclinical study, marketing campaign, economic policy).  \\n3. **Data Availability** – Do you have observational data, experimental data, or both?  \\n4. **Any Prior Knowledge** – Known causal relationships or constraints (e.g.,\\u202f“age” cannot be caused by “income”).  \\n5. **Goal of Counterfactuals** – What kind of counterfactual questions do you want to answer? (e.g.,\\u202f“What if patient\\u202fA had received drug\\u202fB?”)\\n\\nOnce I have this information, I can:\\n\\n- Sketch a plausible directed acyclic graph (DAG) or structural causal model (SCM).  \\n- Discuss identification assumptions (confounding, back‑door paths, instrumental variables, etc.).  \\n- Provide a step‑by‑step construction of counterfactuals using the SCM (e.g., *do*‑interventions, “counterfactual worlds”).  \\n- Generate example counterfactual explanations tailored to your variables.\\n\\nFeel free to share the variables and context, and we’ll build the causal story together!'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variables in the json file {\\n  \"A\": {\\n    \"name\": \"Function Complexity\",\\n    \"description\": \"The number of logical branches, nested conditions, and overall algorithmic complexity of the function.\",\\n    \"weight\": 0.25\\n  },\\n  \"B\": {\\n    \"name\": \"Input Validation\",\\n    \"description\": \"Whether the function checks the validity of its inputs (e.g., length, type, value ranges).\",\\n    \"weight\": 0.20\\n  },\\n  \"C\": {\\n    \"name\": \"Error Handling\",\\n    \"description\": \"The presence and robustness of error handling logic, such as raising exceptions for invalid cases.\",\\n    \"weight\": 0.15\\n  },\\n  \"D\": {\\n    \"name\": \"Dependencies\",\\n    \"description\": \"External modules, services, or global state that the function relies on, influencing isolation in tests.\",\\n    \"weight\": 0.10\\n  },\\n  \"E\": {\\n    \"name\": \"Documentation/Contract\",\\n    \"description\": \"Clarity of the function\\'s docstring, parameter and return type contracts, and adherence to specifications.\",\\n    \"weight\": 0.15\\n  },\\n  \"F\": {\\n    \"name\": \"Edge Cases\",\\n    \"description\": \"The likelihood of encountering unusual or boundary inputs that could reveal hidden bugs.\",\\n    \"weight\": 0.15\\n  }\\n}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the test case import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main(), therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Here is a directed acyclic graph (DAG) in Graphviz **DOT** format that captures the causal relationships among the six code‑quality variables, the generation of the test case, and the final code‑generation node.  \\n\\n```dot\\ndigraph CausalGraph {\\n    // Node shape and common styling\\n    node [shape=box, style=filled, fillcolor=lightgrey, fontname=Helvetica, fontsize=10];\\n\\n    // Variables\\n    A [label=\"A\\\\nFunction Complexity\"];\\n    B [label=\"B\\\\nInput Validation\"];\\n    C [label=\"C\\\\nError Handling\"];\\n    D [label=\"D\\\\nDependencies\"];\\n    E [label=\"E\\\\nDocumentation/Contract\"];\\n    F [label=\"F\\\\nEdge Cases\"];\\n\\n    // Down‑stream processes\\n    G [label=\"G\\\\nTest Case Generation\", fillcolor=lightblue];\\n    H [label=\"H\\\\nCode Generation\", fillcolor=lightgreen];\\n\\n    // 1️⃣ Causal influence among quality attributes\\n    A -> B;          // Complex functions usually need more validation\\n    A -> C;          // Complex logic demands robust error handling\\n    A -> D;          // More complex code tends to use more dependencies\\n    B -> C;          // Validation failures trigger error handling\\n    B -> F;          // Good validation uncovers edge cases\\n    C -> D;          // Error‑handling wrappers may pull in external modules\\n    C -> F;          // Proper error handling exposes hidden edge cases\\n    D -> E;          // External dependencies must be documented\\n    E -> F;          // Clear docs/contract help identify edge cases\\n\\n    // 2️⃣ Influence on test‑case generation\\n    A -> G;\\n    B -> G;\\n    C -> G;\\n    D -> G;\\n    E -> G;\\n    F -> G;\\n\\n    // 3️⃣ Influence on code generation (separate node)\\n    G -> H;          // The test‑case generator drives the final code output\\n}\\n```\\n\\n### Quick Interpretation\\n\\n| Edge | Causal Path |\\n|------|-------------|\\n| `A → B, C, D` | Complexity drives validation, error handling, and dependency use. |\\n| `B → C, F` | Validation informs error handling and surfaces edge cases. |\\n| `C → D, F` | Error handling can introduce dependencies and reveal edge cases. |\\n| `D → E` | Dependencies must be documented. |\\n| `E → F` | Documentation clarifies contract and surfaces edge cases. |\\n| `A–F → G` | All quality factors feed into the test‑case generation process. |\\n| `G → H` | Generated tests inform the final code‑generation step. |\\n\\nFeel free to paste the DOT snippet into any Graphviz‑compatible renderer (e.g., `dot -Tpng file.dot -o graph.png`) to visualise the causal graph.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Function Complexity during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missed Complex Edge Cases\": {\\n    \"description\": \"Test cases that would have been generated to exercise deep logical branches and nested conditions were omitted.\",\\n    \"rationale\": [\\n      \"In the causal graph, Function Complexity (A) directly feeds into Test‑Case Generation (G).\",\\n      \"Because A also drives Input Validation (B), Error Handling (C), and Dependencies (D), the absence of A removes the trigger for generating tests that cover multi‑branch logic, nested conditions, and edge‑case propagation.\",\\n      \"Without these tests, subtle bugs that only appear when the function processes complex inputs can slip through.\",\\n      \"Thus, the probability of such a failure scenario is relatively high due to the strong 0.25 weight on A and its direct G link.\"\\n    ],\\n    \"probability\": 0.40\\n  },\\n  \"Incomplete Dependency Coverage\": {\\n    \"description\": \"Tests that verify interactions with external modules or global state were missing, potentially leading to runtime errors.\",\\n    \"rationale\": [\\n      \"Function Complexity influences Dependencies (D) (edge A → D).\",\\n      \"Dependencies in turn affect Documentation/Contract (E) and Edge Cases (F) before reaching G.\",\\n      \"Without A, the tester’s focus on D diminishes, so the test generator is less likely to create scenarios that exercise external interactions.\",\\n      \"This indirect path, while weaker (weight 0.10 for D), still contributes a moderate chance of oversight.\"\\n    ],\\n    \"probability\": 0.25\\n  },\\n  \"Overall Impact Minimal\": {\\n    \"description\": \"The test suite remains largely adequate because other quality attributes (B, C, D, E, F) still guide test creation.\",\\n    \"rationale\": [\\n      \"The graph shows that B, C, D, E, and F all have direct edges to G.\",\\n      \"Even without A, these variables can produce a reasonably comprehensive set of tests (e.g., validation, error handling, documentation checks).\",\\n      \"Therefore, there is a non‑negligible but lower probability that omitting A does not noticeably degrade the test coverage.\"\\n    ],\\n    \"probability\": 0.20\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Input Validation during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing Invalid‑Input Tests\": {\\n    \"description\": \"Test cases that assert a `ValueError` for vectors not of length three would be omitted.\",\\n    \"rationale\": [\\n      \"Input Validation (B) has a direct causal edge to Test‑Case Generation (G); without B, the generator has no trigger to create length‑check tests.\",\\n      \"B also feeds into Error Handling (C).  If B is ignored, C receives no input‑validation signal, so the error‑handling logic may not be exercised in the suite.\",\\n      \"The weight of B is 0.20, and the path B→G accounts for a substantial portion of G’s total causal input.  Removing it reduces the probability that length‑check tests are produced.\",\\n      \"Consequently, the likelihood of failing to cover the `ValueError` scenario rises.\"\\n    ],\\n    \"probability\": 0.30\\n  },\\n\\n  \"Reduced Edge‑Case Coverage\": {\\n    \"description\": \"The test suite would miss scenarios that probe unusual or boundary inputs, such as empty lists or non‑sequence types.\",\\n    \"rationale\": [\\n      \"B has a direct influence on Edge Cases (F) (B→F).  Edge Cases subsequently feed into G, so when B is ignored, F receives a weaker signal.\",\\n      \"The indirect chain B→F→G explains why boundary‑condition tests are less likely to be generated.\",\\n      \"Because F’s weight is 0.15 and its path through G is part of the overall test‑generation mechanism, omitting B lowers the probability of edge‑case tests by roughly 0.15–0.20.\",\\n      \"Thus, the chance that the test suite fails to cover boundary conditions increases.\"\\n    ],\\n    \"probability\": 0.25\\n  },\\n\\n  \"Weaker Error‑Handling Assertions\": {\\n    \"description\": \"Assertions that confirm the function raises the correct exception types (e.g., `ValueError`, `TypeError`) would be under‑represented.\",\\n    \"rationale\": [\\n      \"B’s influence on Error Handling (C) (B→C) means that, without considering B, C receives no explicit push to test error paths.\",\\n      \"C also feeds into G (C→G).  The combined loss of B→C and C→G edges reduces the overall likelihood that error‑handling checks are included.\",\\n      \"Given the weight of C (0.15) and its contribution to G, the probability that these assertions are omitted is estimated at about 0.20.\",\\n      \"This increases the risk that runtime exceptions slip through untested.\"\\n    ],\\n    \"probability\": 0.20\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Error Handling during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing Exception Assertion Tests\": {\\n    \"description\": \"Test cases that explicitly verify the function raises `ValueError` for non‑length‑3 vectors or `TypeError` for non‑sequence inputs would be omitted.\",\\n    \"rationale\": [\\n      \"In the DAG, Error Handling (C) has a direct causal edge to Test‑Case Generation (G) (C → G).\",\\n      \"When the tester ignores C, the generator has no trigger to create the `assertRaises(ValueError/TypeError)` assertions that are already present in the supplied test suite.\",\\n      \"C also drives Error Handling logic in the code; without considering C, the tester fails to probe that code path.\",\\n      \"Because C carries a weight of 0.15 and accounts for a significant share of the overall input to G, the probability that such exception‑handling tests are missing rises to roughly 35\\u202f%.\"\\n    ],\\n    \"probability\": 0.35\\n  },\\n\\n  \"Reduced Dependency‑Interaction Coverage\": {\\n    \"description\": \"Tests that validate how the function behaves when it interacts with external modules or global state (e.g., through dependency injection or mocking) would be less likely to appear.\",\\n    \"rationale\": [\\n      \"Error Handling influences Dependencies via the edge C → D.  Without C, the signal to include dependency‑wrapping tests is weakened.\",\\n      \"Dependencies (D) then affect Documentation/Contract (E) and Edge Cases (F), which in turn feed into G.  Thus, the indirect path C → D → G is broken.\",\\n      \"Since D has a weight of 0.10 and the indirect contribution to G is modest, the probability of missing dependency‑interaction tests is estimated at about 20\\u202f%.\"\\n    ],\\n    \"probability\": 0.20\\n  },\\n\\n  \"Diminished Edge‑Case Detection\": {\\n    \"description\": \"Boundary and unusual input scenarios (empty lists, non‑sequence types, etc.) would receive less coverage in the generated tests.\",\\n    \"rationale\": [\\n      \"C contributes to Edge Cases through C → F.  Ignoring C removes that input signal to F.\",\\n      \"Edge Cases (F) have a direct edge to G, so the absence of C reduces the overall weight that F can provide to test‑generation.\",\\n      \"Given F’s weight of 0.15, the loss of its contribution to G translates to an approximate 25\\u202f% chance that edge‑case tests are omitted.\"\\n    ],\\n    \"probability\": 0.25\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Dependencies during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing Dependency‑Interaction Tests\": {\\n    \"description\": \"Test cases that would validate the function’s interaction with external modules or global state (e.g., mock‑ing a vector source or ensuring isolation from shared resources) would not be generated.\",\\n    \"rationale\": [\\n      \"In the causal graph, Dependencies (D) have a direct edge to Test‑Case Generation (G) (D → G).\",\\n      \"When the tester ignores D, the generator lacks the trigger to create scenarios that exercise external dependencies or mock‑based setups.\",\\n      \"Although D’s weight is 0.10, the edge D → G accounts for a non‑negligible share of the causal influence on G; thus, omission raises the probability that such tests are missing.\",\\n      \"Given the moderate weight of D relative to other factors, we estimate this omission occurs about 22\\u202f% of the time.\"\\n    ],\\n    \"probability\": 0.22\\n  },\\n  \"Reduced Documentation/Contract Coverage\": {\\n    \"description\": \"Tests that confirm the function’s public contract (type hints, docstring correctness, and dependency‑related specifications) would be under‑represented.\",\\n    \"rationale\": [\\n      \"Dependencies influence Documentation/Contract through the edge D → E.  E, in turn, feeds into Test‑Case Generation (E → G).\",\\n      \"If D is ignored, the signal to E is weakened, leading to fewer contract‑related assertions in the suite.\",\\n      \"The indirect path D → E → G is shorter and carries the 0.10 weight of D, suggesting a lower but still noticeable risk of missing such tests.\",\\n      \"We approximate the probability of this effect at around 13\\u202f%.\"\\n    ],\\n    \"probability\": 0.13\\n  },\\n  \"Diminished Edge‑Case Detection\": {\\n    \"description\": \"Boundary or unusual input scenarios (e.g., empty vectors, non‑sequence arguments) would receive less coverage in the generated tests.\",\\n    \"rationale\": [\\n      \"Dependencies influence Edge Cases via the chain D → E → F (since E → F is present).  Edge Cases (F) has a direct edge to G.\",\\n      \"Without considering D, the chain that feeds F is weakened, reducing the weight that F can contribute to G.\",\\n      \"Given F’s weight of 0.15 and the indirect contribution from D, the chance of missing edge‑case tests is roughly 18\\u202f%.\",\\n      \"Thus, the probability that boundary‑condition checks are omitted is estimated at 0.18.\"\\n    ],\\n    \"probability\": 0.18\\n  }\\n}\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Documentation/Contract during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing Contract‑Verification Tests\": {\\n    \"description\": \"Assertions that explicitly confirm the public contract of `cross_product` (e.g., correct type hints, docstring wording, and declared dependencies) would not be generated.\",\\n    \"rationale\": [\\n      \"Documentation/Contract (E) has a direct causal edge to Test‑Case Generation (G) – E\\u202f→\\u202fG.  Ignoring E removes this trigger.\",\\n      \"All tests that validate the function’s signature or docstring are therefore absent from the automatically generated suite.\",\\n      \"E carries a weight of 0.15, which constitutes a non‑trivial share of the total causal influence on G (in addition to the direct E\\u202f→\\u202fG edge).\",\\n      \"Given this moderate weight, we estimate that contract‑verification tests are omitted with a probability of about 0.18.\"\\n    ],\\n    \"probability\": 0.18\\n  },\\n\\n  \"Reduced Edge‑Case Coverage via Documentation\": {\\n    \"description\": \"Boundary or unusual input scenarios (e.g., empty vectors, non‑sequence arguments) would receive less coverage in the generated tests.\",\\n    \"rationale\": [\\n      \"E influences Edge Cases (F) through the chain E\\u202f→\\u202fF.  Edge Cases then feed into G via F\\u202f→\\u202fG.\",\\n      \"Without considering Documentation/Contract, the signal that drives F is weakened, so F contributes less weight to G.\",\\n      \"F has a weight of 0.15, but the indirect contribution from E is only 0.15\\u202f×\\u202f0.15\\u202f≈\\u202f0.0225 of the total G input.\",\\n      \"This loss translates to an estimated 12\\u202f% chance that edge‑case tests are omitted.\"\\n    ],\\n    \"probability\": 0.12\\n  },\\n\\n  \"Diminished Dependency‑Contract Tests\": {\\n    \"description\": \"Tests that confirm how external dependencies are documented and used (e.g., parameter contracts for injected vector sources) would be under‑represented.\",\\n    \"rationale\": [\\n      \"Dependencies (D) influence Documentation/Contract via D\\u202f→\\u202fE.  Ignoring E weakens the signal from D to E.\",\\n      \"E also feeds into Test‑Case Generation (E\\u202f→\\u202fG).  Thus the indirect path D\\u202f→\\u202fE\\u202f→\\u202fG is broken when E is omitted.\",\\n      \"The weight of D is 0.10, and its indirect contribution to G through E is modest, suggesting a lower but still noticeable risk.\",\\n      \"We approximate the probability of missing such dependency‑contract tests at about 0.09.\"\\n    ],\\n    \"probability\": 0.09\\n  }\\n}\\n```\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software tester had not considered the variable Edge Cases during the generation of the import unittest\\nfrom typing import Sequence, List\\n\\ndef cross_product(a: Sequence[float], b: Sequence[float]) -> List[float]:\\n    \"\"\"\\n    Compute the cross product of two 3‑D vectors.\\n    \"\"\"\\n    if len(a) != 3 or len(b) != 3:\\n        raise ValueError(\"Both vectors must be of length 3.\")\\n    a1, a2, a3 = a\\n    b1, b2, b3 = b\\n    return [\\n        a2 * b3 - a3 * b2,\\n        a3 * b1 - a1 * b3,\\n        a1 * b2 - a2 * b1,\\n    ]\\n\\nclass TestCrossProduct(unittest.TestCase):\\n    def test_basic_cross_product(self):\\n        a = [1, 2, 3]\\n        b = [4, 5, 6]\\n        expected = [-3, 6, -3]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_with_zero_vector(self):\\n        a = [0, 0, 0]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_orthogonal_vectors(self):\\n        a = [1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, 1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_parallel_vectors(self):\\n        a = [2, 4, 6]\\n        b = [1, 2, 3]\\n        expected = [0, 0, 0]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_negative_vector(self):\\n        a = [-1, 0, 0]\\n        b = [0, 1, 0]\\n        expected = [0, 0, -1]\\n        result = cross_product(a, b)\\n        self.assertEqual(result, expected)\\n\\n    def test_cross_product_return_type(self):\\n        a = (1, 2, 3)\\n        b = [4, 5, 6]\\n        result = cross_product(a, b)\\n        self.assertIsInstance(result, list)\\n        self.assertEqual(len(result), 3)\\n\\n    def test_cross_product_invalid_length(self):\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2], [3, 4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([1, 2, 3], [4, 5])\\n        with self.assertRaises(ValueError):\\n            cross_product([], [])\\n\\n    def test_cross_product_non_sequence_inputs(self):\\n        with self.assertRaises(TypeError):\\n            cross_product([1, 2, 3], None)\\n        with self.assertRaises(TypeError):\\n            cross_product(None, [1, 2, 3])\\n\\nif __name__ == \"__main__\":\\n    unittest.main() test? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```json\\n{\\n  \"Missing Extreme‑Value Edge‑Case Tests\": {\\n    \"description\": \"Test cases that would probe how `cross_product` handles extreme or special numeric inputs (e.g., `float(\\'nan\\')`, `float(\\'inf\\')`, extremely large or small numbers) would not be generated.\",\\n    \"rationale\": [\\n      \"In the DAG, Edge Cases (F) have a direct causal edge to Test‑Case Generation (G) – F\\u202f→\\u202fG.  Ignoring F removes this trigger.\",\\n      \"The weight attached to F is 0.15, representing a non‑trivial share of the total causal influence on G.\",\\n      \"Consequently, the probability that the automatically generated test suite lacks tests for extreme numeric values is approximately the weight of F, i.e. about 15\\u202f%.\"\\n    ],\\n    \"probability\": 0.15\\n  },\\n  \"Reduced Boundary‑Vector‑Length Coverage\": {\\n    \"description\": \"Tests that cover boundary conditions for vector lengths (e.g., vectors of length 0, 1, or 2, and vectors that are exactly the minimum or maximum allowed size) would be under‑represented.\",\\n    \"rationale\": [\\n      \"Boundary‑length checks are a subset of the Edge‑Case domain.  Since Edge Cases influence Test‑Case Generation via F\\u202f→\\u202fG, ignoring F suppresses all edge‑case–related length tests.\",\\n      \"A conservative estimate for missing such tests is slightly lower than the overall F weight because a portion of the boundary checks might also be generated by the Input‑Validation sub‑branch.  We therefore approximate the missing‑test probability at ~12\\u202f%.\",\\n      \"Thus, the likelihood that the test suite fails to include length‑boundary tests is roughly 12\\u202f%.\"\\n    ],\\n    \"probability\": 0.12\\n  },\\n  \"Lack of Tests for Invalid Argument Types Beyond `None`\": {\\n    \"description\": \"The suite would miss scenarios where non‑sequence types (e.g., `int`, `float`, `dict`, `list` of non‑numeric elements) are passed to `cross_product`—tests that are normally produced by Edge Cases.\",\\n    \"rationale\": [\\n      \"Type‑related edge‑case tests are also governed by Edge Cases.  When F is ignored, the generator does not produce these tests.\",\\n      \"Given the Edge‑Case weight of 0.15, the chance of omitting such type‑boundary tests is somewhat lower because a few of them might still be triggered by Exception Handling or Input Validation; an estimate of about 8\\u202f% captures this reduced overlap.\",\\n      \"Hence, the probability that the generated suite lacks type‑boundary tests beyond the already present `None` checks is around 8\\u202f%.\"\\n    ],\\n    \"probability\": 0.08\\n  }\\n}\\n```'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac528e",
   "metadata": {},
   "source": [
    "# Scenario A - interpretability - step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70ebcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_3 = causal_template['scenario_a']['step3']['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7125505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.'},\n",
       " {'role': 'user',\n",
       "  'content': '[CAUSAL TASK] Giving the following variables in the json file {FACTORS}, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the summary {SUMMARY}, therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.'},\n",
       " {'role': 'user',\n",
       "  'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_introspection_factors_3(introspection_chat_history):\n",
    "    factors = []\n",
    "    function = None\n",
    "    function_message = introspection_chat_history[3]['content']\n",
    "    function = extract_function_name(function_message)\n",
    "    factors_message = introspection_chat_history[5]['content']\n",
    "    cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", factors_message.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    data = json.loads(cleaned)\n",
    "    factors=list(find_name(data))\n",
    "    return function, function_message, factors, factors_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5afd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "chat_history_3 = []\n",
    "last_response = ''\n",
    "messagges = copy.deepcopy(messages_3)\n",
    "input_file= 'ollama_gpt-oss:latest_step1_step2_sptep3_15.json'\n",
    "introspection_messaages =json.load(open(\"output/introspection/\"+input_file))['scenario_a']['step3']['messages']\n",
    "\n",
    "_, summary, nodes, factors_message = process_introspection_factors(introspection_messaages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in causal inference and counterfactual reasoning. Your job is to infer a causal graph from a set of variables and draft counterfactual explanations.\n",
      "-----\n",
      "Sure! To get started, could you please share:\n",
      "\n",
      "1. **The list of variables** you’re interested in (e.g., “age”, “income”, “treatment”, “outcome”, etc.).\n",
      "2. **Any data you have** (even a small sample or summary statistics) or at least a description of how these variables are measured and related in the real world.\n",
      "3. **Your specific goal** for the counterfactuals (e.g., “What would happen to outcome X if we intervened on Y?”).\n",
      "4. **Any domain constraints** or prior knowledge you already have (e.g., known causal direction, temporal ordering, or impossibilities).\n",
      "\n",
      "Once I have that, I can:\n",
      "- Construct a plausible causal graph (directed acyclic graph) based on the information and your domain knowledge.\n",
      "- Identify the back‑door, front‑door, or instrumental variables needed.\n",
      "- Draft counterfactual explanations for the scenarios you care about.\n",
      "\n",
      "Feel free to provide as much detail as you can, and we’ll dive into the inference and explanations!\n",
      "[CAUSAL TASK] Giving the following variables in the json file ```json\n",
      "{\n",
      "  \"A\": {\n",
      "    \"name\": \"Code Length\",\n",
      "    \"description\": \"The number of lines or overall size of the implementation; shorter code tends to be more amenable to a concise summary.\",\n",
      "    \"weight\": 0.15\n",
      "  },\n",
      "  \"B\": {\n",
      "    \"name\": \"Type Annotations\",\n",
      "    \"description\": \"Presence of explicit typing hints (e.g., Sequence[float], List[float]) that clarify input and output contracts.\",\n",
      "    \"weight\": 0.10\n",
      "  },\n",
      "  \"C\": {\n",
      "    \"name\": \"Error Handling\",\n",
      "    \"description\": \"Inclusion of validation logic (such as length checks and ValueError raises) indicating robustness and edge‑case awareness.\",\n",
      "    \"weight\": 0.10\n",
      "  },\n",
      "  \"D\": {\n",
      "    \"name\": \"Documentation Quality\",\n",
      "    \"description\": \"The richness of the docstring—parameters, return description, and explanatory context—guiding the summarizer’s content focus.\",\n",
      "    \"weight\": 0.25\n",
      "  },\n",
      "  \"E\": {\n",
      "    \"name\": \"Domain Relevance\",\n",
      "    \"description\": \"The function’s applicability to common fields (physics, graphics, engineering) which motivates a more thorough explanation.\",\n",
      "    \"weight\": 0.20\n",
      "  },\n",
      "  \"F\": {\n",
      "    \"name\": \"Readability\",\n",
      "    \"description\": \"Clarity of variable names and overall style, influencing how easily a human can comprehend and summarize the code.\",\n",
      "    \"weight\": 0.10\n",
      "  },\n",
      "  \"G\": {\n",
      "    \"name\": \"Function Complexity\",\n",
      "    \"description\": \"Algorithmic complexity (e.g., O(1) for cross‑product) affecting how many details are highlighted in the summary.\",\n",
      "    \"weight\": 0.10\n",
      "  }\n",
      "}\n",
      "```, generate a causal graph that explains how they influence each other. Consider that those variables are influencing the generation of the summary The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations., therefore the code generation should be a separate node in the graph. The outcome must be in Graphviz DOT format.\n",
      "-----\n",
      "```dot\n",
      "digraph CausalGraph {\n",
      "  node [shape=box];\n",
      "\n",
      "  /* Variables */\n",
      "  A [label=\"A: Code Length\"];\n",
      "  B [label=\"B: Type Annotations\"];\n",
      "  C [label=\"C: Error Handling\"];\n",
      "  D [label=\"D: Documentation Quality\"];\n",
      "  E [label=\"E: Domain Relevance\"];\n",
      "  F [label=\"F: Readability\"];\n",
      "  G [label=\"G: Function Complexity\"];\n",
      "\n",
      "  /* Additional nodes */\n",
      "  CodeGen [label=\"Code Generation\"];\n",
      "  Summary [label=\"Summary\"];\n",
      "\n",
      "  /* Influence of features on code generation */\n",
      "  A -> CodeGen;\n",
      "  B -> CodeGen;\n",
      "  C -> CodeGen;\n",
      "  D -> CodeGen;\n",
      "  E -> CodeGen;\n",
      "  F -> CodeGen;\n",
      "  G -> CodeGen;\n",
      "\n",
      "  /* Internal causal links among features */\n",
      "  G -> A;          /* Complexity tends to increase code length */\n",
      "  A -> F;          /* Longer code often reduces readability */\n",
      "  B -> D;          /* Type annotations improve documentation quality */\n",
      "  C -> F;          /* Error handling enhances readability */\n",
      "\n",
      "  /* Direct influence on the summary */\n",
      "  D -> Summary;    /* Better documentation leads to richer summaries */\n",
      "  E -> Summary;    /* Domain relevance drives summary detail */\n",
      "  F -> Summary;    /* More readable code eases summarization */\n",
      "  G -> Summary;    /* Higher complexity may lead to more elaborate summaries */\n",
      "  A -> Summary;    /* Longer code often requires more explanation */\n",
      "\n",
      "  /* Code generation leads to the summary */\n",
      "  CodeGen -> Summary;\n",
      "}\n",
      "```\n",
      "\n",
      "This Graphviz DOT script represents a directed acyclic graph where each variable influences others as described, and the `Code Generation` node serves as an intermediary that ultimately produces the `Summary`.\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Code Length during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Summary Omission of Code Length Detail\": {\n",
      "    \"description\": \"The generated summary would no longer mention or emphasize how short the cross_product function is, potentially making the summary appear less concise than the actual code.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Code Length (A) has a direct edge to Summary, meaning the summary generator normally uses A to adjust its length and detail.\",\n",
      "      \"By intervening so that A is not considered, we remove that edge, so the summary relies only on the remaining predictors (D, E, F, G, CodeGen).\",\n",
      "      \"Since A contributes 15 % of the explanatory weight for Summary and directly influences the perceived conciseness, its removal is likely to cause the summary to overstate the function’s verbosity.\",\n",
      "      \"Thus the most noticeable effect is the omission of a specific mention that the function is short.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  },\n",
      "  \"Misrepresentation of Readability\": {\n",
      "    \"description\": \"The summary may overestimate the readability of the function, because readability (F) is partly driven by Code Length (A), which is no longer taken into account.\",\n",
      "    \"rationale\": [\n",
      "      \"The graph shows an edge A → F, indicating that longer code tends to reduce readability.\",\n",
      "      \"If A is ignored during summarization, the algorithm cannot correct for this relationship and will treat the function as more readable than it actually is.\",\n",
      "      \"This misrepresentation will propagate to Summary via the F → Summary edge.\",\n",
      "      \"Since readability carries a 10 % weight, the effect is moderate but noticeable.\"\n",
      "    ],\n",
      "    \"probability\": 0.35\n",
      "  },\n",
      "  \"Potential Summary Length Over‑estimation\": {\n",
      "    \"description\": \"The overall length of the summary may be longer than necessary, as the algorithm compensates for the missing code‑length cue by relying more heavily on other predictors (e.g., Domain Relevance and Documentation Quality).\",\n",
      "    \"rationale\": [\n",
      "      \"Without the A → Summary edge, the summary generator’s predictive model must adjust to fit the observed outcome using the remaining variables.\",\n",
      "      \"Domain Relevance (E) and Documentation Quality (D) have higher weights (20 % and 25 %) and both push for richer, longer explanations.\",\n",
      "      \"The absence of the concise‑code cue removes a balancing factor that would normally temper this tendency, leading to an over‑lengthy summary.\",\n",
      "      \"Thus the counterfactual predicts a statistically likely increase in summary verbosity.\"\n",
      "    ],\n",
      "    \"probability\": 0.30\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Type Annotations during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Omission of Explicit Type Hints in the Summary\": {\n",
      "    \"description\": \"The generated summary would describe the function’s inputs and outputs in generic terms (e.g., “sequences of numbers”) instead of specifying the concrete `Sequence[float]`/`List[float]` contracts that the code actually declares.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, the Type Annotations node (B) has a direct influence on the Code Generation node (CodeGen) and on Documentation Quality (D).\",\n",
      "      \"By *not* considering B during summarization, the edge B → CodeGen is effectively removed, meaning the summarizer no longer receives the explicit typing information that the code generator could expose.\",\n",
      "      \"Furthermore, the B → D edge is removed, so Documentation Quality receives no boost from the presence of type hints. Since D has a strong direct effect on Summary (weight = 0.25), the summary loses one of its richest sources of detail.\",\n",
      "      \"The missing type‑hint signal is the most visible consequence, so the counterfactual is most likely to manifest as a generic description of the function’s contracts.\",\n",
      "      \"Given that B’s weight is 0.10 and its influence on Summary is mediated through D (0.25), we estimate a moderate‑to‑high probability that this omission occurs.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  },\n",
      "  \"Diminished Documentation Detail in the Summary\": {\n",
      "    \"description\": \"The summary would contain fewer explanatory sentences about the function’s purpose, inputs, and error handling, appearing less thorough than the actual code’s documentation suggests.\",\n",
      "    \"rationale\": [\n",
      "      \"Type Annotations are linked to Documentation Quality via B → D. Removing B deprives the summarizer of a key cue that the documentation is detailed and well‑structured.\",\n",
      "      \"D influences Summary directly with a weight of 0.25. Without the boost from B, the overall expected value of D drops, leading the model to generate a leaner description.\",\n",
      "      \"The loss of documentation richness is therefore a secondary but still observable effect after the omission of explicit type hints.\",\n",
      "      \"Because D has a comparatively high weight, the probability of this outcome is still substantial, though slightly lower than the first counterfactual.\"\n",
      "    ],\n",
      "    \"probability\": 0.35\n",
      "  },\n",
      "  \"Potential Misinterpretation of Input Contracts\": {\n",
      "    \"description\": \"The summarizer might incorrectly state that the function accepts any iterable of numbers, neglecting the requirement that each input must be a sequence of exactly three floats, which could mislead readers about valid usage.\",\n",
      "    \"rationale\": [\n",
      "      \"The edge B → CodeGen carries information about the exact shape and type constraints of the parameters. When B is ignored, CodeGen no longer passes this constraint to the summarizer.\",\n",
      "      \"The summary, lacking this detail, defaults to a broader description of input expectations.\",\n",
      "      \"This misinterpretation is a logical consequence of missing the B → CodeGen influence, but it is comparatively less likely than the other two effects because it depends on higher‑level reasoning about input structure.\",\n",
      "      \"Thus we assign it a lower probability, yet still non‑negligible, reflecting the fact that the graph shows a direct path from B to the summarization content via CodeGen.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Error Handling during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Omission of Input‑Validation Detail\": {\n",
      "    \"description\": \"The generated summary would not mention that the function verifies the length of each input vector and raises a ValueError when the condition is not met.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Error Handling (C) has a direct edge to Code Generation (CodeGen) and an indirect edge to Summary via CodeGen → Summary.\",\n",
      "      \"When C is ignored, the summarizer no longer receives the explicit information that a validation step exists in the code, removing the path C → CodeGen → Summary.\",\n",
      "      \"Since this validation step is a salient feature of the function’s behaviour, its absence is the most obvious change in the text.\",\n",
      "      \"Given C’s weight of 0.10 and its influence on Summary through CodeGen, we estimate a moderate‑to‑high likelihood that this omission occurs.\"\n",
      "    ],\n",
      "    \"probability\": 0.45\n",
      "  },\n",
      "  \"Understated Robustness and Edge‑Case Awareness\": {\n",
      "    \"description\": \"The summary will portray the function as less robust, failing to emphasize the presence of defensive checks that guard against invalid inputs.\",\n",
      "    \"rationale\": [\n",
      "      \"C also influences Readability (F) through C → F, and Readability directly affects Summary (F → Summary).\",\n",
      "      \"By not considering C, the summarizer misses the cue that the code’s readability is enhanced by explicit error handling.\",\n",
      "      \"Consequently, the summary will be leaner on remarks about robustness, which is a secondary but still noticeable effect.\",\n",
      "      \"Because this pathway involves two edges (C → F → Summary) and the total weight of the signal is small, the probability is lower than the first counterfactual but still appreciable.\"\n",
      "    ],\n",
      "    \"probability\": 0.30\n",
      "  },\n",
      "  \"Simplified Function Behaviour Description\": {\n",
      "    \"description\": \"The summarizer may describe the cross‑product formula without referencing the required input shape or the pre‑condition checks, potentially misleading readers about valid usage.\",\n",
      "    \"rationale\": [\n",
      "      \"The path C → CodeGen → Summary carries information about the exact parameter contract (exactly three numeric elements).\",\n",
      "      \"Ignoring C removes this path, so the summarizer defaults to a generic description of the function’s inputs.\",\n",
      "      \"This effect is plausible but depends on higher‑level inference about the code’s intent, making it the least likely among the three.\",\n",
      "      \"Nonetheless, because the graph shows a direct link from C to the summarization content via CodeGen, we assign a non‑zero probability.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Documentation Quality during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Omission of Parameter and Return Details\": {\n",
      "    \"description\": \"The summary would describe the function in vague terms, stating only that it “takes two sequences of numbers” and returns a list of numbers, without listing the exact parameter names, types, or the return format that the docstring provides.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Documentation Quality (D) has a direct edge to Summary (D → Summary), and it also receives information from Type Annotations (B → D).\",\n",
      "      \"By not considering D, the summarizer effectively removes the D → Summary path, so the rich information that the docstring contributes (parameter names, type hints, and return description) is lost.\",\n",
      "      \"Because D carries 25 % of the total explanatory weight for Summary, its absence is the most visible change, leading to a generic description of inputs and outputs.\",\n",
      "      \"Given the substantial weight of D, the probability that this omission occurs is high.\"\n",
      "    ],\n",
      "    \"probability\": 0.6\n",
      "  },\n",
      "  \"Understatement of Usage Examples and Context\": {\n",
      "    \"description\": \"The generated summary would fail to mention the practical contexts (physics, graphics, engineering) or any example use‑cases that are typically highlighted in the docstring, making the function appear less applicable to real‑world scenarios.\",\n",
      "    \"rationale\": [\n",
      "      \"The docstring often contains example snippets and domain‑specific explanations, which are encapsulated in the Documentation Quality node (D).\",\n",
      "      \"Eliminating D from the summarization process removes the D → Summary influence that would normally bring these contextual details into the output.\",\n",
      "      \"Other variables (E, A, G) still influence the summary, but they do not convey the same level of concrete usage examples, so the resulting description is noticeably less illustrative.\",\n",
      "      \"This effect is secondary to the loss of parameter details but still likely to occur because D is a primary source of such examples.\"\n",
      "    ],\n",
      "    \"probability\": 0.4\n",
      "  },\n",
      "  \"Generic Summary with Emphasis on Code Length\": {\n",
      "    \"description\": \"The summary would lean more heavily on Code Length (A) and Function Complexity (G) to justify its brevity, resulting in a plain statement such as “a concise utility” without the explanatory richness normally provided by the docstring.\",\n",
      "    \"rationale\": [\n",
      "      \"When D is ignored, the summarizer no longer receives the docstring cues that counterbalance the influence of A and G.\",\n",
      "      \"Edges A → Summary and G → Summary remain, so the model may over‑emphasize these factors, leading to a short, generic explanation.\",\n",
      "      \"This pathway involves only two remaining edges (A → Summary, G → Summary) and is less informative than the omitted docstring content, so the likelihood is lower but still non‑negligible.\",\n",
      "      \"Thus the probability of this outcome is estimated at a moderate level.\"\n",
      "    ],\n",
      "    \"probability\": 0.3\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Domain Relevance during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"Omission of Domain Context and Use‑Case Examples\": {\n",
      "    \"description\": \"The generated summary would no longer reference the physics, graphics, or engineering domains in which the cross‑product function is commonly used, and it would omit any illustrative example or application note.\",\n",
      "    \"rationale\": [\n",
      "      \"In the causal graph, Domain Relevance (E) has a direct edge to Summary (E → Summary) with a weight of 0.20, and an indirect edge through Code Generation (E → CodeGen → Summary).\",\n",
      "      \"Intervening on E by not considering it removes both the direct and indirect paths that normally convey domain‑specific language and example snippets from the code or its docstring into the summary.\",\n",
      "      \"Because domain context is a salient feature that distinguishes a general utility from a domain‑specific tool, its absence is the most obvious change in the text.\",\n",
      "      \"Given the moderate weight of E and its single direct influence on Summary, we estimate a relatively high likelihood that the summary will omit this contextual detail.\"\n",
      "    ],\n",
      "    \"probability\": 0.55\n",
      "  },\n",
      "  \"Reduced Emphasis on Practical Applicability\": {\n",
      "    \"description\": \"The summary would present the function as a generic utility without highlighting its relevance to real‑world problems such as physics simulations, computer graphics, or engineering calculations.\",\n",
      "    \"rationale\": [\n",
      "      \"The edge E → Summary directly informs the summarizer that the function is useful in certain domains. Removing this cue weakens the model’s motivation to include sentences that tie the function to specific application areas.\",\n",
      "      \"Other variables (e.g., D, F, G) still influence the summary, but none of them carry explicit references to domain usage, so the resulting description becomes less illustrative.\",\n",
      "      \"Because this effect is mediated by a single edge with weight 0.20, it is likely but less dramatic than the complete loss of domain examples.\"\n",
      "    ],\n",
      "    \"probability\": 0.35\n",
      "  },\n",
      "  \"Minor Compression of Summary Length\": {\n",
      "    \"description\": \"The overall length of the summary may be slightly reduced, as the summarizer would rely more on Code Length, Complexity, and Documentation Quality cues that do not compensate for the missing domain‑relevance signal.\",\n",
      "    \"rationale\": [\n",
      "      \"E contributes to Summary via a direct influence that often encourages adding explanatory sentences about use‑cases. Without this influence, the summarizer may lean on the remaining edges (A → Summary, G → Summary, D → Summary) which are more concise.\",\n",
      "      \"The pathway for this change involves only the removal of the E → Summary edge, making it a subtle effect compared to the outright omission of domain examples.\",\n",
      "      \"Given the lower weight of this pathway relative to the main domain‑context edge, the probability of this outcome is lower but still non‑zero.\"\n",
      "    ],\n",
      "    \"probability\": 0.20\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'role': 'user', 'content': '[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable {NODE} during the generation of the summary: {SUMMARY}? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.'}\n",
      "[COUNTERFACTUAL TASK] What would have changed or happened if the software developer had not considered the variable Readability during the generation of the summary: The `cross_product` function is a concise utility for calculating the three‑dimensional vector cross product. It accepts two input sequences (`a` and `b`) that must each contain exactly three numeric values; if either vector is not of length three, the function immediately raises a `ValueError` to prevent invalid calculations. The implementation destructures each input into its three components (e.g., `a1, a2, a3`) and then applies the standard cross‑product formula: the first component is `a2 * b3 - a3 * b2`, the second is `a3 * b1 - a1 * b3`, and the third is `a1 * b2 - a2 * b1`. The result is returned as a new `List[float]`, preserving the order of the resulting vector’s components. This function is useful whenever vector arithmetic is required, such as in physics simulations, computer graphics, or engineering computations.? Provide at most three counterfactual answers. Estimate a probability of occurrence for each answer based solely on the causal graph in Graphviz DOT format. The outcome must be contained in a json format in which the first level comprises the name of the counterfactual answer; the second level comprises a description of the answer, a step by step of the rationale of that counterfactual answer, and the probability of occurrence.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "first_node = nodes.pop(0)\n",
    "last_message = {}\n",
    "def run(message, node):\n",
    "    \n",
    "    message['content'] = process_messages(message, None, factors_message, node, None, summary)\n",
    "    print(message['content'])\n",
    "    print(\"-----\")\n",
    "    chat_history_3.append(message)\n",
    "    last_response = llm.call(messages=chat_history_3)\n",
    "    #print({'role':'assistant','content':last_response})\n",
    "    print(last_response)\n",
    "    chat_history_3.append({\"role\": \"assistant\", \"content\": last_response})\n",
    "\n",
    "for message in messagges:\n",
    "    last_message = copy.deepcopy(message)\n",
    "    run(message , first_node)\n",
    "\n",
    "while nodes:\n",
    "    print(last_message)\n",
    "    run(copy.deepcopy(last_message), nodes.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25541629",
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\n",
    "    'scenario_a': {\n",
    "        'step1': {'messages': chat_history},\n",
    "        'step2': {'messages': chat_history_2},\n",
    "        'step3': {'messages': chat_history_3}\n",
    "    }\n",
    "}\n",
    "file = \"output/interpretability/\"+ llm.model.replace(\"/\",\"_\")+\"_step1__step2_step3_\"+ str(exec_count) +\".json\"\n",
    "with open(file, \"w\") as f:\n",
    "    json.dump(output, f, indent=4)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
